{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve speed of SVC in sklearn might not be supported by some hardware if causes errors - ignore\n",
    "# from sklearnex import patch_sklearn\n",
    "# patch_sklearn(\"SVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running in drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from google.colab import drive\n",
    "# # drive.mount('/content/drive')\n",
    "\n",
    "# from pathlib import Path\n",
    "# import os\n",
    "\n",
    "# # CHANGE ONLY THIS PATH AND EVERYTHING SHOULD RUN\n",
    "# # Vlad's drive\n",
    "# # notebooks_path = Path.cwd()/'drive/MyDrive/calcification-detection-project/calcification_detecion/calc-det/notebooks'\n",
    "# Joaquin's drive\n",
    "# notebooks_path = Path.cwd()/'drive/MyDrive/calcification_detection/calc-det/notebooks'\n",
    "# repo_path = notebooks_path.parent\n",
    "# os.chdir(str(notebooks_path))\n",
    "\n",
    "# thispath = Path.cwd().resolve()\n",
    "# import sys; sys.path.insert(0, str(thispath.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inbreast_pngs_path = str(repo_path / 'data/INbreast\\ Release\\ 1.0/AllPNGs/full_imgs')\n",
    "# inbreast_img_meta_path = str(repo_path / 'data/INbreast\\ Release\\ 1.0/images_metadata.csv')\n",
    "# inbreast_rois_meta_path = str(repo_path / 'data/INbreast\\ Release\\ 1.0/rois_metadata.csv')\n",
    "# inbreast_masks_path = str(repo_path / 'data/INbreast\\ Release\\ 1.0/AllMasks/full_imgs')\n",
    "\n",
    "# det_checkpoints_path = str(repo_path / 'deep_learning/detection_models/checkpoints/')\n",
    "# class_checkpoints_path = str(repo_path / 'deep_learning/classification_models/checkpoints/')\n",
    "\n",
    "# !mkdir '/home/INbreast Release 1.0/'\n",
    "# !mkdir '/home/INbreast Release 1.0/AllPNGs/'\n",
    "# !mkdir '/home/INbreast Release 1.0/AllMasks/'\n",
    "\n",
    "# !rsync -rva $inbreast_pngs_path '/home/INbreast Release 1.0/AllPNGs/'\n",
    "# !rsync -rva $inbreast_img_meta_path '/home/INbreast Release 1.0/images_metadata.csv'\n",
    "# !rsync -rva $inbreast_rois_meta_path '/home/INbreast Release 1.0/rois_metadata.csv'\n",
    "# !rsync -rva $inbreast_masks_path '/home/INbreast Release 1.0/AllMasks/'\n",
    "\n",
    "# !rsync -rva $det_checkpoints_path '/home/detection_checkpoints'\n",
    "# !mv /home/detection_checkpoints/checkpoints/* '/home/detection_checkpoints/'\n",
    "# !rmdir '/home/detection_checkpoints/checkpoints/'\n",
    "# !rsync -rva $class_checkpoints_path '/home/classification_checkpoints'\n",
    "# !mv /home/classification_checkpoints/checkpoints/* '/home/classification_checkpoints/'\n",
    "# !rmdir '/home/classification_checkpoints/checkpoints/'\n",
    "\n",
    "# !pip install transformers\n",
    "# !pip install SimpleITK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "notebooks_path = Path.cwd()\n",
    "repo_path = notebooks_path.parent\n",
    "os.chdir(str(notebooks_path))\n",
    "thispath = Path.cwd().resolve()\n",
    "import sys; sys.path.insert(0, str(thispath.parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the dataset, for accessing the images and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database.dataset import INBreast_Dataset\n",
    "\n",
    "db = INBreast_Dataset(\n",
    "    return_lesions_mask=True,\n",
    "    level='image',\n",
    "    max_lesion_diam_mm=None,\n",
    "    extract_patches=False,\n",
    "    partitions=['validation'],\n",
    "    lesion_types=['calcification', 'cluster'],\n",
    "    cropped_imgs=True,\n",
    "    keep_just_images_of_lesion_type=False,\n",
    "    use_muscle_mask=False,\n",
    "    ignore_diameter_px=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a function to run the model and store results over all samples in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from metrics.metrics_utils import get_froc_df_of_img, get_tp_fp_fn_center_patch_criteria\n",
    "\n",
    "def get_froc_dataframe_from_set(db, detector, results_path, store_time = False):\n",
    "    # get normal images\n",
    "    normal_imgs_ids = db.get_free_of_selected_lesions_imgs_ids()\n",
    "\n",
    "    # define paths to store intermediate results\n",
    "    results_path = Path(results_path)\n",
    "    if not results_path.exists():\n",
    "        results_path.mkdir(parents=True, exist_ok=True)\n",
    "    frocs_df_path = results_path / 'froc_df.csv'\n",
    "    times_path = results_path / 'times.p'\n",
    "    froc_dfs = []\n",
    "    times = []\n",
    "\n",
    "    # get the detections for each image in the database\n",
    "    for idx in tqdm(range(len(db))):\n",
    "        # get sample\n",
    "        db_sample = db[idx]\n",
    "        image = db_sample['img']\n",
    "        image_id = db_sample['img_id']\n",
    "        image_mask = db_sample['lesion_mask']\n",
    "\n",
    "        start = time.time()\n",
    "        detections = detector.detect(image)\n",
    "        times.append(time.time()-start)\n",
    "\n",
    "        # reformat detections\n",
    "        detections_centers_and_radius = np.stack(detections['candidate_coordinates'].values).astype(int)\n",
    "        detections_scores = detections['confidence'].values.reshape(-1, 1)\n",
    "        # retain the centers and scores:\n",
    "        candidates = np.concatenate([detections_centers_and_radius, detections_scores], axis = 1)\n",
    "\n",
    "        # compare with labels\n",
    "        tp, fp, fn, _ = get_tp_fp_fn_center_patch_criteria(\n",
    "            candidates, image_mask, None, 14, use_euclidean_dist=True, scores_passed=True)\n",
    "        candidates = pd.concat([tp, fp], axis=0, ignore_index=True)\n",
    "\n",
    "        # generate standard dataframe\n",
    "        froc_df = get_froc_df_of_img(\n",
    "            candidates, fn, candidates['score'], image_id, (image_id in normal_imgs_ids))\n",
    "        \n",
    "        froc_dfs.append(froc_df)\n",
    "    \n",
    "    # store full\n",
    "    froc_dfs = pd.concat(froc_dfs, ignore_index=True)\n",
    "    froc_dfs.to_csv(frocs_df_path)\n",
    "    if store_time:\n",
    "        with open(times_path, 'wb') as f:\n",
    "            pickle.dump(times, f)\n",
    "    return froc_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning.ml_detector import DetectorML\n",
    "from general_utils.plots import plot_froc, plot_several_frocs, add_detections_overlay\n",
    "from metrics.metrics import froc_curve\n",
    "from metrics.metrics_utils import best_th_froc_curve\n",
    "import general_utils.utils as utils\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instatiate the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading model...\n",
      "INFO:root:Selected keep_sens_thr=1.0\n",
      "Max_conf_thr_required to keep given sensitivity is 0.00035\n",
      "Filtering out all candidates with confidence <=0.00035 is estimated to reduce FP by 4.15 %\n"
     ]
    }
   ],
   "source": [
    "model_chkpt_path = str(repo_path / 'machine_learning/checkpoints/cascade_models.pkl')\n",
    "detector = DetectorML(model_chkpt_path, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run on the complete validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/62 [00:00<?, ?it/s]INFO:root:Starting candidates proposal...\n",
      "INFO:root:Starting feature extraction...\n",
      "INFO:root:Classifying...\n",
      "INFO:root:sklearn.svm.SVC.predict_proba: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.decision_function: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict_proba: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.decision_function: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09996569 0.01498582 0.16612328 0.07060275 0.03941088 0.22071874\n",
      " 0.03616301 0.05171201 0.01277346 0.8152492 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:NMS...\n",
      "  0%|          | 0/62 [01:14<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1207, 1277, 1]) list([984, 2654, 1]) list([45, 2934, 2]) ...\n",
      " list([58, 2735, 0]) list([96, 2947, 0]) list([961, 2047, 0])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_path = repo_path.parent / 'detections_dl/aia_ml_cascaded_svc'\n",
    "froc_dfs = get_froc_dataframe_from_set(db, detector, results_path, store_time = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1685, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of labels across predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jseia/Desktop/ml-dl/calc-det/notebooks/detection_by_aia_plus_ml_analysis.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jseia/Desktop/ml-dl/calc-det/notebooks/detection_by_aia_plus_ml_analysis.ipynb#ch0000017?line=0'>1</a>\u001b[0m froc_dfs\u001b[39m.\u001b[39;49mlabel\u001b[39m.\u001b[39mvalue_counts()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'label'"
     ]
    }
   ],
   "source": [
    "froc_dfs.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens, avgs_fp_per_image, thresholds = froc_curve(froc_dfs, non_max_supression=True, cut_on_50fpi=True)\n",
    "th, tpr, fpr = best_th_froc_curve(np.asarray(sens), np.asarray(avgs_fp_per_image), np.asarray(thresholds))\n",
    "print(f'Threshold: {th}, TPR: {tpr}, FPR: {fpr}')\n",
    "sens.append(sens[-1])\n",
    "avgs_fp_per_image.append(50)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "ax.scatter(fpr, tpr, label='selected point', c='r')\n",
    "plot_froc(avgs_fp_per_image, sens, label='Validation Set', title='FROC Resnet50 FasterRCNN (d_resnet50_00)', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate the model\n",
    "model_chkpt_path = str(repo_path / 'machine_learning/checkpoints/cascade_models.pkl')\n",
    "detector = DetectorML(model_chkpt_path)\n",
    "\n",
    "# get image\n",
    "idx = 22\n",
    "db_sample = db[idx]\n",
    "image = db_sample['img']\n",
    "image_id = db_sample['img_id']\n",
    "image_mask = db_sample['lesion_mask']\n",
    "\n",
    "# get detections\n",
    "detections = detector.detect(image)\n",
    "\n",
    "# reformat detections\n",
    "detections_centers_and_radius = np.asarray(detections['candidate_coordinates'].values, dtype=int)\n",
    "detections_scores = detections['confidence'].values.reshape(-1, 1)\n",
    "# retain the centers and scores:\n",
    "detections = np.concatenate([detections_centers_and_radius, detections_scores], axis = 1)\n",
    "\n",
    "# Generate the images\n",
    "image = add_detections_overlay(\n",
    "    image, detections, image_mask, conf_thr=0.8870506882667542, k=0, need_labeling = True)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(25, 15))\n",
    "ax.set_title('Faster RCNN - Resnet50')\n",
    "ax.imshow(image)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store to dcm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate the model\n",
    "model_chkpt_path = str(repo_path / 'machine_learning/checkpoints/cascade_models.pkl')\n",
    "detector = DetectorML(model_chkpt_path)\n",
    "\n",
    "# get image\n",
    "idx = 22\n",
    "db_sample = db[idx]\n",
    "image = db_sample['img']\n",
    "image_id = db_sample['img_id']\n",
    "image_mask = db_sample['lesion_mask']\n",
    "\n",
    "# get detections\n",
    "detections = detector.detect(image)\n",
    "\n",
    "# reformat detections\n",
    "detections_centers_and_radius = np.asarray(detections['candidate_coordinates'].values, dtype=int)\n",
    "detections_scores = detections['confidence'].values.reshape(-1, 1)\n",
    "# retain the centers and scores:\n",
    "detections = np.concatenate([detections_centers_and_radius, detections_scores], axis = 1)\n",
    "\n",
    "fields = ['img_id', 'case_id', 'side', 'view', 'breast_bbox']\n",
    "fields = db.img_df.loc[db.img_df.img_id == image_id, fields].values[0]\n",
    "view = 'ML' if fields[3] == 'MLO' else fields[3]\n",
    "dcm_img_name = f'{fields[0]}_{fields[1]}_MG_{fields[2]}_{view}_ANON.dcm'\n",
    "dcm_path = repo_path / 'data/INbreast Release 1.0/AllDICOMs/'\n",
    "original_dcm_filepath = dcm_path/dcm_img_name\n",
    "breast_bbox = fields[-1]\n",
    "\n",
    "output_filepath = repo_path.parent / 'ml_det_example.dcm'\n",
    "\n",
    "detections_df = pd.DataFrame(detections, columns=['x', 'y', 'radius', 'score'])\n",
    "detections_df = detections_df.loc[detections_df.score >= 0.21540279686450958, :]\n",
    "\n",
    "!rm $output_filepath\n",
    "!cp $original_dcm_filepath $repo_path.parent\n",
    "\n",
    "dcm_path = repo_path / 'data/INbreast Release 1.0/AllDICOMs/'\n",
    "original_dcm_filepath = dcm_path/dcm_img_name\n",
    "\n",
    "utils.store_as_dcm(\n",
    "    image, detections_df, original_dcm_filepath, output_filepath, breast_bbox)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('calc_det')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f094a5cfaa0fb3b1e730adb1bd2a385aed1bdbc34460cd7c5bc1913497751e38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
