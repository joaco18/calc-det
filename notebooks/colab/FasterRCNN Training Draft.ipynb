{"cells":[{"cell_type":"markdown","metadata":{"id":"DfPPQ6ztJhv4"},"source":["# TorchVision Tutorial Based Pipeline\n","\n","Following TORCHVISION OBJECT DETECTION FINETUNING TUTORIAL at https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42441,"status":"ok","timestamp":1655963296205,"user":{"displayName":"Joaquín Seia","userId":"08240948874484507233"},"user_tz":-120},"id":"TxmB2lvRWXDh","outputId":"be8ab427-4b6f-40e6-d939-7e52008566bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":605,"status":"ok","timestamp":1655963296801,"user":{"displayName":"Joaquín Seia","userId":"08240948874484507233"},"user_tz":-120},"id":"pe1K-SB0mvXa"},"outputs":[],"source":["from pathlib import Path\n","import os\n","# Vlad's drive\n","# repo_path = Path.cwd()/'drive/MyDrive/calcification-detection-project/calcification_detecion/calc-det'\n","# Joaquin's drive\n","repo_path = Path.cwd()/'drive/MyDrive/calcification_detection/calc-det/notebooks'\n","os.chdir(str(repo_path))\n","\n","thispath = Path.cwd().resolve()\n","import sys; sys.path.insert(0, str(thispath.parent))"]},{"cell_type":"markdown","metadata":{"id":"yugM37XlXo3O"},"source":["Copy extracted patches used for detection (224 size with stride 100) to the local machine. ***Needs to be done once per machine instantization***. \n","\n","~ 3 minutes to complete"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":17826,"status":"ok","timestamp":1655963786163,"user":{"displayName":"Joaquín Seia","userId":"08240948874484507233"},"user_tz":-120},"id":"wVl1uCNjm3RK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"249329f2-ca32-4367-9ea4-9d1f86e640b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["^C\n","Archive:  /home/data_rois.zip\n","  End-of-central-directory signature not found.  Either this file is not\n","  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n","  latter case the central directory and zipfile comment will be found on\n","  the last disk(s) of this archive.\n","unzip:  cannot find zipfile directory in one of /home/data_rois.zip or\n","        /home/data_rois.zip.zip, and cannot find /home/data_rois.zip.ZIP, period.\n","mv: cannot stat '/home/home/vzalevskyi/projects/data_rois': No such file or directory\n","rm: cannot remove '/home/home': No such file or directory\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting SimpleITK\n","  Downloading SimpleITK-2.1.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n","\u001b[K     |████████████████████████████████| 48.4 MB 49 kB/s \n","\u001b[?25hInstalling collected packages: SimpleITK\n","Successfully installed SimpleITK-2.1.1.2\n"]}],"source":["# # Vlad's Drive\n","# # !cp -r /content/drive/MyDrive/calcification-detection-project/calcification_detecion/new_data_rois/data_rois.zip /home/\n","# # Joaquin's Drive\n","# !cp -r /content/drive/MyDrive/calcification_detection/rois_all_method/data_rois_224.zip /home/data_rois.zip\n","# !unzip /home/data_rois.zip -d /home\n","# !mv /home/home/vzalevskyi/projects/data_rois /home/data_rois\n","# !rm -r /home/home\n","# !pip install transformers\n","# !pip install SimpleITK"]},{"cell_type":"markdown","metadata":{"id":"L5yvZUprj4ZN"},"source":["Now let's instantiate the model and the optimizer"]},{"cell_type":"markdown","metadata":{"id":"XAd56lt4kDxc"},"source":["And now let's train the model for 10 epochs, evaluating at the end of every epoch."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1655963790534,"user":{"displayName":"Joaquín Seia","userId":"08240948874484507233"},"user_tz":-120},"id":"IJLfF2QXLEc9"},"outputs":[],"source":["cfg = {\n","    'model': {\n","        'activation': 'LeakyReLU',\n","        'bloc_act': None,\n","        'use_middle_activation': True,\n","        'dropout': 0.4,\n","        'fc_dims': None,\n","        'freeze_weights': False,\n","        'backbone': 'net2',\n","        'pretrained': True,\n","        'checkpoint_path': None,\n","        'anchor_sizes': [12, 14],\n","        'anchor_ratios': [1.0],\n","        'num_classes': 2\n","    },\n","    'dataset': {\n","        'extract_patches': False,\n","        'delete_previous': False,\n","        'extract_patches_method': 'all',\n","        'patch_size': 224,\n","        'stride': 100,\n","        'min_breast_fraction_roi': 0.7,\n","        'n_jobs': -1,\n","        'cropped_imgs': True,\n","        'ignore_diameter_px': 15,\n","        'train_neg_to_pos_ratio': None,\n","        'balancing_seed': 0,\n","        'normalization': 'min_max',\n","        'get_lesion_bboxes': True,\n","        'for_detection_net': True,\n","        'patch_images_path': '/home/data_rois/',\n","        'detection_bbox_size':14\n","    },\n","    'dataloaders': {\n","        'train_batch_size': 8,\n","        'val_batch_size': 16\n","    },\n","    'data_aug': {\n","        'prob': 0\n","    },\n","    'training': {\n","        'criterion': 'BCEWithLogitsLoss',\n","        'optimizer': 'Adam',\n","        'optimizer_args': {\n","            'lr': 0.0001 #, 'momentum': 0.9\n","        },\n","        'lr_scheduler': 'StepLR',\n","        'lr_scheduler_args': {\n","            'step_size': 3, 'gamma': 0.1\n","        },\n","        'n_epochs': 30,\n","        'best_metric': 'f1_score',\n","        'resume_training': False,\n","        'early_stopping': True,\n","        'early_stopping_args':{\n","            'min_diff': 0.0001,\n","            'max_epoch': 3\n","        },\n","        'log_iters': 100,\n","        'max_iters_per_epoch': None\n","        },\n","    'experiment_name': '32_resnet_01'\n","}\n","\n","import yaml\n","\n","cfg_path = str(thispath.parent.parent/'calc-det/deep_learning/detection_models/config.yml')\n","with open(cfg_path, 'w') as yaml_file:\n","    yaml.dump(cfg, yaml_file, default_flow_style=False)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3862,"status":"ok","timestamp":1655963794957,"user":{"displayName":"Joaquín Seia","userId":"08240948874484507233"},"user_tz":-120},"id":"ql2wxoLj8SO2"},"outputs":[],"source":["from pathlib import Path\n","thispath = Path.cwd().resolve()\n","import sys; sys.path.insert(0, str(thispath.parent))\n","\n","import logging\n","import torch\n","import torchvision\n","import yaml\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","\n","import deep_learning.dl_utils as dl_utils\n","from deep_learning.dataset.dataset import INBreast_Dataset_pytorch\n","from deep_learning.classification_models.models.base_classifier import CNNClasssifier\n","from deep_learning.detection_models.train import train_model\n","\n","logging.basicConfig(level=logging.INFO)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","def main():\n","    # read the configuration file\n","    config_path = str(thispath.parent.parent/'calc-det/deep_learning/detection_models/config.yml')\n","    with open(config_path, \"r\") as ymlfile:\n","        cfg = yaml.safe_load(ymlfile)\n","\n","    # for colab it needs to be specified additionally\n","    dataset_arguments = cfg['dataset']\n","\n","    # use the configuration for the dataset\n","    dataset_arguments = cfg['dataset']\n","    dataset_arguments['patch_images_path'] = Path(dataset_arguments['patch_images_path'])\n","    datasets = {\n","        'train': INBreast_Dataset_pytorch(\n","            partitions=['train'], neg_to_pos_ratio=dataset_arguments['train_neg_to_pos_ratio'],\n","            **dataset_arguments),\n","        'val': INBreast_Dataset_pytorch(\n","            partitions=['validation'], neg_to_pos_ratio=None, **dataset_arguments)\n","    }\n","\n","    # use the configuration for the dataloaders\n","    def collate_fn(batch):\n","        return tuple(zip(*batch))\n","    dataloaders = {\n","        'val': DataLoader(\n","            datasets['val'], batch_size=cfg['dataloaders']['val_batch_size'],\n","            num_workers=4, collate_fn=collate_fn, drop_last=False),\n","        'train': DataLoader(\n","            datasets['train'], batch_size=cfg['dataloaders']['train_batch_size'],\n","            shuffle=True, collate_fn=collate_fn, num_workers=4, drop_last=False)\n","    }\n","\n","    # model settings\n","    if cfg['model']['checkpoint_path'] is not None:\n","        model_ckpt = torch.load(cfg['model']['checkpoint_path'])\n","        model = dl_utils.get_model_from_checkpoint(model_ckpt, cfg['model']['freeze_weights'])\n","    else:\n","        model = CNNClasssifier(\n","            activation=getattr(nn, cfg['model']['activation'])(),\n","            dropout=cfg['model']['dropout'],\n","            fc_dims=cfg['model']['fc_dims'],\n","            freeze_weights=cfg['model']['freeze_weights'],\n","            backbone=cfg['model']['backbone'],\n","            pretrained=cfg['model']['pretrained'],\n","        )\n","        model = model.model\n","\n","    modules = list(model.children())[:-2]      # delete the last fc layers.\n","    last_submodule_childs = list(modules[-1][-1].children())\n","    for i in range(len(last_submodule_childs)-1, -1, -1):\n","        if hasattr(last_submodule_childs[i], 'out_channels'):\n","            out_channels = last_submodule_childs[i].out_channels\n","            break\n","    model_backbone = nn.Sequential(*modules)\n","    model_backbone.out_channels = out_channels\n","    anchor_generator = AnchorGenerator(\n","        sizes=(cfg['model']['anchor_sizes'],),\n","        aspect_ratios=(cfg['model']['anchor_ratios'],))\n","\n","    roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n","        featmap_names=['0'], output_size=7, sampling_ratio=2)\n","\n","    # put the pieces together inside a FasterRCNN model\n","    model = FasterRCNN(\n","        model_backbone,\n","        num_classes=cfg['model']['num_classes'],\n","        rpn_anchor_generator=anchor_generator,\n","        box_roi_pool=roi_pooler,\n","        image_mean=[0., 0., 0.],\n","        image_std=[1., 1., 1.],\n","    )\n","\n","    model.to(device)\n","\n","    # training configs\n","    optimizer = getattr(optim, cfg['training']['optimizer'])\n","    optimizer = optimizer(model.parameters(), **cfg['training']['optimizer_args'])\n","\n","    scheduler = getattr(lr_scheduler, cfg['training']['lr_scheduler'])\n","    scheduler = scheduler(optimizer, **cfg['training']['lr_scheduler_args'])\n","\n","    # train the model\n","    train_model(datasets, dataloaders, model, optimizer, scheduler, cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":277,"referenced_widgets":["8b79e2d0b68a42138b11f14265c3026e","c65961dbe03e4680bf3dce427cbfa7ba","8b3d669c52ac42cd93fc41ea8e8c94a0","0e0e36388de2470d8e7b4679cbfc1a6f","8e62be93e8434fd28eb8d295811f00f1","a12c54c7ebb7448a86501af53a2fd9a3","3507236705d749a4a2624e4b7307cf82","250db432008c48adb1096177d2965b39","332db217fce64d9a956f620198bf57bf","79e390807e0d47ea822711336074b2fe","e8445be28fb7423da3567debb497d5a8"]},"id":"C0SMxDo0OKSn","outputId":"df4489e7-ccb9-41d3-9e06-74c8fa342ddb"},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/calcification_detection/calc-det/deep_learning/dataset/dataset.py:52: DtypeWarning: Columns (16,17) have mixed types.Specify dtype option on import or set low_memory=False.\n","  return_lesions_mask=get_lesion_bboxes, max_lesion_diam_mm=None, use_muscle_mask=False\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b79e2d0b68a42138b11f14265c3026e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:Storing experiment in: /content/drive/MyDrive/calcification_detection/data/deepl_runs/d_resnet50_06\n"]},{"output_type":"stream","name":"stdout","text":["creating index...\n","index created!\n","Epoch: [0]  [  0/729]  eta: 1:13:28  lr: 0.000000  loss: 1.6504 (1.6504)  loss_classifier: 0.7561 (0.7561)  loss_box_reg: 0.0024 (0.0024)  loss_objectness: 0.8242 (0.8242)  loss_rpn_box_reg: 0.0677 (0.0677)  time: 6.0468  data: 0.4182  max mem: 9834\n","Epoch: [0]  [100/729]  eta: 0:11:06  lr: 0.000014  loss: 0.1261 (0.4128)  loss_classifier: 0.0428 (0.1406)  loss_box_reg: 0.0108 (0.0074)  loss_objectness: 0.0564 (0.2317)  loss_rpn_box_reg: 0.0194 (0.0331)  time: 1.0113  data: 0.0191  max mem: 11723\n","Epoch: [0]  [200/729]  eta: 0:09:07  lr: 0.000028  loss: 0.0864 (0.2716)  loss_classifier: 0.0282 (0.0918)  loss_box_reg: 0.0222 (0.0130)  loss_objectness: 0.0254 (0.1403)  loss_rpn_box_reg: 0.0120 (0.0266)  time: 1.0103  data: 0.0208  max mem: 11723\n","Epoch: [0]  [300/729]  eta: 0:07:20  lr: 0.000041  loss: 0.0655 (0.2148)  loss_classifier: 0.0204 (0.0717)  loss_box_reg: 0.0222 (0.0188)  loss_objectness: 0.0166 (0.1023)  loss_rpn_box_reg: 0.0078 (0.0220)  time: 1.0103  data: 0.0213  max mem: 11723\n","Epoch: [0]  [400/729]  eta: 0:05:36  lr: 0.000055  loss: 0.0712 (0.1808)  loss_classifier: 0.0225 (0.0596)  loss_box_reg: 0.0224 (0.0205)  loss_objectness: 0.0154 (0.0817)  loss_rpn_box_reg: 0.0084 (0.0189)  time: 1.0092  data: 0.0210  max mem: 11723\n","Epoch: [0]  [500/729]  eta: 0:03:53  lr: 0.000069  loss: 0.0608 (0.1614)  loss_classifier: 0.0183 (0.0525)  loss_box_reg: 0.0182 (0.0221)  loss_objectness: 0.0151 (0.0694)  loss_rpn_box_reg: 0.0064 (0.0173)  time: 1.0218  data: 0.0346  max mem: 11723\n"]}],"source":["# cfg['model']['activation'] = 'LeakyReLU'\n","# cfg['model']['dropout'] = 0.4\n","# cfg['model']['fc_dims'] = None\n","cfg['model']['backbone'] = 'resnet50'\n","cfg['model']['pretrained'] = True\n","cfg['model']['checkpoint_path'] = '/content/drive/MyDrive/drive_vlad/deepl_runs/resnet50_05/resnet50_05.pt'\n","cfg['model']['anchor_sizes'] = [7, 14]\n","cfg['model']['anchor_ratios'] = [1.0]\n","cfg['model']['num_classes'] = 2\n","\n","cfg['dataset']['train_neg_to_pos_ratio'] = None\n","cfg['dataset']['normalization'] = 'z_score'\n","\n","cfg['dataloaders']['train_batch_size'] = 6\n","cfg['dataloaders']['val_batch_size'] = 12\n","\n","cfg['training']['optimizer'] = 'Adam'\n","cfg['training']['optimizer_args'] = {'lr': 0.0001}\n","cfg['training']['lr_scheduler'] = 'StepLR'\n","cfg['training']['lr_scheduler_args'] = {'step_size': 3, 'gamma': 0.1}\n","cfg['training']['n_epochs'] = 20\n","cfg['training']['early_stopping'] = False\n","cfg['training']['early_stopping_args'] = {'min_diff': 0.0001, 'max_epoch': 3}\n","cfg['training']['log_iters'] = 100\n","cfg['training']['best_metric'] = 'AP_IoU_0.50_all'\n","cfg['training']['max_iters_per_epoch'] = None\n","\n","cfg['experiment_name'] = 'd_resnet50_06'\n","\n","cfg_path = str(thispath.parent.parent/'calc-det/deep_learning/detection_models/config.yml')\n","with open(cfg_path, 'w') as yaml_file:\n","    yaml.dump(cfg, yaml_file, default_flow_style=False)\n","main()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"FasterRCNN Training Draft.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"aab0ec0e679e9c9fe5e8a1739a642d8456688678f7924db8d58b62c9618a230e"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"8b79e2d0b68a42138b11f14265c3026e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c65961dbe03e4680bf3dce427cbfa7ba","IPY_MODEL_8b3d669c52ac42cd93fc41ea8e8c94a0","IPY_MODEL_0e0e36388de2470d8e7b4679cbfc1a6f"],"layout":"IPY_MODEL_8e62be93e8434fd28eb8d295811f00f1"}},"c65961dbe03e4680bf3dce427cbfa7ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a12c54c7ebb7448a86501af53a2fd9a3","placeholder":"​","style":"IPY_MODEL_3507236705d749a4a2624e4b7307cf82","value":"100%"}},"8b3d669c52ac42cd93fc41ea8e8c94a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_250db432008c48adb1096177d2965b39","max":102530333,"min":0,"orientation":"horizontal","style":"IPY_MODEL_332db217fce64d9a956f620198bf57bf","value":102530333}},"0e0e36388de2470d8e7b4679cbfc1a6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79e390807e0d47ea822711336074b2fe","placeholder":"​","style":"IPY_MODEL_e8445be28fb7423da3567debb497d5a8","value":" 97.8M/97.8M [00:00&lt;00:00, 177MB/s]"}},"8e62be93e8434fd28eb8d295811f00f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a12c54c7ebb7448a86501af53a2fd9a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3507236705d749a4a2624e4b7307cf82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"250db432008c48adb1096177d2965b39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"332db217fce64d9a956f620198bf57bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79e390807e0d47ea822711336074b2fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8445be28fb7423da3567debb497d5a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}