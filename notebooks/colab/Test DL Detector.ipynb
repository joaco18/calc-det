{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","from pathlib import Path\n","import os\n","repo_path = Path.cwd()/'drive/MyDrive/calcification-detection-project/calcification_detecion/calc-det'\n","os.chdir(str(repo_path))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmRFqKltordM","executionInfo":{"status":"ok","timestamp":1655734368458,"user_tz":-120,"elapsed":1752,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}},"outputId":"cfde478e-3f31-4022-e737-fc34b6611ca1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# !cp -r /content/drive/MyDrive/calcification-detection-project/calcification_detecion/new_data_rois/data_rois.zip /home/\n","# !unzip /home/data_rois.zip -d /home\n","# !mv /home/home/vzalevskyi/projects/data_rois /home/data_rois\n","# !rm -r /home/home"],"metadata":{"id":"9yJ9R5JToraf","executionInfo":{"status":"ok","timestamp":1655734368458,"user_tz":-120,"elapsed":5,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"T5MRgFYborYN","executionInfo":{"status":"ok","timestamp":1655734368458,"user_tz":-120,"elapsed":4,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"oaEfBzsRol73","executionInfo":{"status":"ok","timestamp":1655734371001,"user_tz":-120,"elapsed":2546,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"outputs":[],"source":["from pathlib import Path\n","thispath = Path.cwd().resolve()\n","import sys; sys.path.insert(0, str(thispath.parent))\n","\n","from deep_learning.dataset.dataset import INBreast_Dataset_pytorch\n","\n","import copy\n","import torch\n","import time\n","import random\n","import pickle\n","from general_utils.plots import simple_im_show, simple_im_show2\n","from collections import Counter\n","\n","from metrics.metrics import froc_curve\n","from metrics.metrics_utils import get_froc_df_of_img, get_froc_df_of_many_imgs_features, get_tp_fp_fn_center_patch_criteria\n","\n","from deep_learning.dataset.dataset import ImgCropsDataset\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","\n","from torch.optim import lr_scheduler\n","from torchvision import models\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm import tqdm\n","\n","from database.dataset import INBreast_Dataset\n","import torchvision.transforms.functional as F\n","from torchvision.utils import draw_bounding_boxes\n","from deep_learning.models.base_classifier import CNNClasssifier\n","import torchvision\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n","\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","def show(imgs):\n","    if not isinstance(imgs, list):\n","        imgs = [imgs]\n","    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n","    for i, img in enumerate(imgs):\n","        img = img.detach()\n","        img = F.to_pil_image(img)\n","        axs[0, i].imshow(np.asarray(img))\n","        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n","        \n","\n","def get_instance_segmentation_model(num_classes):\n","\n","    # LOAD OUR BEST RESNET\n","    # exp_path / f'{cfg[\"experiment_name\"]}.pt'\n","    best_model_path = '/content/drive/MyDrive/calcification-detection-project/calcification_detecion/data/deepl_runs/resnet50_05/resnet50_05.pt'\n","    chkpt_path = '/content/drive/MyDrive/calcification-detection-project/calcification_detecion/data/deepl_runs/resnet50_05/resnet50_05_chkpt.pt'\n","    # exp_path / f'{cfg[\"experiment_name\"]}_chkpt.pt'\n","    resnet50_model = CNNClasssifier(backbone='resnet50', fc_dims=None).model\n","    # load best model weights before returning\n","    # best_model = torch.load(best_model_path)\n","    # resnet50_model.load_state_dict(best_model['model_state_dict'])\n","\n","    # resnet50_model.fc = Identity()\n","\n","    modules = list(resnet50_model.children())[:-2]      # delete the last fc layer.\n","    resnet50_model_backbone = nn.Sequential(*modules)\n","\n","    \n","\n","    backbone = resnet50_model_backbone#.features\n","    backbone.out_channels = 2048#?1280\n","\n","    # let's make the RPN generate 5 x 3 anchors per spatial\n","    # location, with 5 different sizes and 3 different aspect\n","    # ratios. We have a Tuple[Tuple[int]] because each feature\n","    # map could potentially have different sizes and\n","    # aspect ratios\n","    anchor_generator = AnchorGenerator(sizes=((16, 32),),\n","                                    aspect_ratios=((1.0),))\n","\n","    # let's define what are the feature maps that we will\n","    # use to perform the region of interest cropping, as well as\n","    # the size of the crop after rescaling.\n","    # if your backbone returns a Tensor, featmap_names is expected to\n","    # be [0]. More generally, the backbone should return an\n","    # OrderedDict[Tensor], and in featmap_names you can choose which\n","    # feature maps to use.\n","    roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n","                                                    output_size=7,\n","                                                    sampling_ratio=2)\n","\n","    # put the pieces together inside a FasterRCNN model\n","    model = FasterRCNN(backbone,\n","                    num_classes=num_classes,\n","                    rpn_anchor_generator=anchor_generator,\n","                    box_roi_pool=roi_pooler)\n","\n","    return model\n"]},{"cell_type":"code","source":["datapath = Path('/content/drive/MyDrive/calcification-detection-project/calcification_detecion/calc-det/data/INbreast Release 1.0')"],"metadata":{"id":"DmDnLXpmp9sd","executionInfo":{"status":"ok","timestamp":1655734371002,"user_tz":-120,"elapsed":6,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VbcfTzZ-ol7_","executionInfo":{"status":"ok","timestamp":1655734372371,"user_tz":-120,"elapsed":1373,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}},"outputId":"c63f8756-a562-4a3e-e0e3-e4f8b38f43c1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/calcification-detection-project/calcification_detecion/calc-det/deep_learning/dataset/dataset.py:50: DtypeWarning: Columns (16,17) have mixed types.Specify dtype option on import or set low_memory=False.\n","  return_lesions_mask=get_lesion_bboxes, max_lesion_diam_mm=None, use_muscle_mask=False\n"]}],"source":["dataset_arguments = {\n","    'extract_patches': False,\n","    'delete_previous': False,\n","    'extract_patches_method': 'all',\n","    'patch_size': 224,\n","    'stride': 100,\n","    'min_breast_fraction_roi': 0.7,\n","    'n_jobs': -1,\n","    'cropped_imgs': True,\n","    'ignore_diameter_px': 15,\n","    'neg_to_pos_ratio': None,\n","    'balancing_seed': 0,\n","    'normalization': 'min_max',\n","    'get_lesion_bboxes': True,\n","    'for_detection_net': True,\n","    'patch_images_path': Path( '/home/data_rois/'), # FOR GDRIVE '/home/data_rois/' '/home/vzalevskyi/projects/vlads_datarois/data_rois/'\n","\n","    # ONLY FOR COLAB\n","    'imgpath':datapath/'AllMasks',\n","    'mask_path': datapath/'AllMasks',\n","    'dfpath':datapath\n","}\n","\n","image_datasets = {\n","    'train': INBreast_Dataset_pytorch(\n","        partitions=['train'],\n","        **dataset_arguments\n","    ),\n","    'val': INBreast_Dataset_pytorch(\n","        partitions=['validation'],\n","\n","        **dataset_arguments\n","    ),\n","    \n","}"]},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"],"metadata":{"id":"BTsI0kTusBuX","executionInfo":{"status":"ok","timestamp":1655734372372,"user_tz":-120,"elapsed":6,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_8wM6Hxwol8E","executionInfo":{"status":"ok","timestamp":1655734380467,"user_tz":-120,"elapsed":8099,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}},"outputId":"767903b2-3629-4107-a2f9-8244e72b8294"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["FasterRCNN(\n","  (transform): GeneralizedRCNNTransform(\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","  )\n","  (backbone): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  (rpn): RegionProposalNetwork(\n","    (anchor_generator): AnchorGenerator()\n","    (head): RPNHead(\n","      (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (cls_logits): Conv2d(2048, 2, kernel_size=(1, 1), stride=(1, 1))\n","      (bbox_pred): Conv2d(2048, 8, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): RoIHeads(\n","    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0'], output_size=(7, 7), sampling_ratio=2)\n","    (box_head): TwoMLPHead(\n","      (fc6): Linear(in_features=100352, out_features=1024, bias=True)\n","      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (box_predictor): FastRCNNPredictor(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":7}],"source":["model = get_instance_segmentation_model(2)\n","model = model.to(device)\n","model.load_state_dict(torch.load(thispath/'test_dettection/test_model.pt'))\n","model.eval()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"deXuPygdol8F","executionInfo":{"status":"ok","timestamp":1655734380468,"user_tz":-120,"elapsed":15,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"outputs":[],"source":["# for i in range(3):\n","\n","#     timage, ttarget = image_datasets['val'][i]\n","#     with torch.no_grad():\n","\n","#         pred_target = model([timage])[0]\n","\n","\n","#     result = draw_bounding_boxes((255*timage).to(torch.uint8), ttarget['boxes'], colors=['blue']*len(ttarget['boxes']),  width=1)\n","#     show(result)\n","#     result = draw_bounding_boxes((255*timage).to(torch.uint8), pred_target['boxes'], colors=['red']*len(pred_target['boxes']),  width=1)\n","#     show(result)\n","\n","#     print(ttarget['boxes'])\n","#     print(pred_target['boxes'])\n","    \n","#     plt.show()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"kzXx50oBol8G","executionInfo":{"status":"ok","timestamp":1655734380468,"user_tz":-120,"elapsed":14,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"outputs":[],"source":["class DL_Detector:\n","    def __init__(self, dl_model):\n","        self.model = dl_model\n","        \n","    def detect(image, patch_size=224, stride=224, min_breast_fraction_patch=0.5):\n","        img_crops = ImgCropsDataset(image, patch_size, stride, min_breast_fraction_patch)\n","        "]},{"cell_type":"code","execution_count":10,"metadata":{"id":"UjU4UdEBol8G","executionInfo":{"status":"ok","timestamp":1655734380469,"user_tz":-120,"elapsed":14,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"outputs":[],"source":["full_imgs_db = INBreast_Dataset(\n","    return_lesions_mask=True,\n","    level='image',\n","    max_lesion_diam_mm=None,\n","    extract_patches=False,\n","    partitions=['validation'],\n","    lesion_types=['calcification', 'cluster'],\n","    cropped_imgs=True,\n","    keep_just_images_of_lesion_type=False,\n","    use_muscle_mask=False,\n","    ignore_diameter_px=15\n",")"]},{"cell_type":"code","source":["def rescale_prediced_bboxes(bbox_pred, patch_coords):\n","    # new_boxes = [[int(x[0] + patch_coords[0][0]), int(x[1] + patch_coords[0][1]), int(x[2] + patch_coords[0][0]), int(x[3] + patch_coords[0][1])] for xidx, x in enumerate(bbox_pred['boxes'])]\n","    new_boxes_wradius = [[int(x[2] + patch_coords[0][0] - 8), int(x[3] + patch_coords[0][1] - 8), 8, bbox_pred['scores'][xidx].cpu()] for xidx, x in enumerate(bbox_pred['boxes']) if len(bbox_pred['boxes'])]\n","    return new_boxes_wradius"],"metadata":{"id":"nNG-qBmN6bnY","executionInfo":{"status":"ok","timestamp":1655734380469,"user_tz":-120,"elapsed":14,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["idx = 0\n","img = full_imgs_db[idx]['img']\n","lesion_bboxes = full_imgs_db[idx]['lesion_bboxes']\n","img_id = full_imgs_db[idx]['img_id']\n","lesion_mask = full_imgs_db[idx]['lesion_mask']"],"metadata":{"id":"cpzCqjlpbGr7","executionInfo":{"status":"ok","timestamp":1655734381850,"user_tz":-120,"elapsed":1395,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["crops_dataset = ImgCropsDataset(\n","    img=img,\n","    patch_size=224,\n","    stride=200,\n","    min_breast_fraction_patch=0.7\n",")\n","crops_dataloader = DataLoader(\n","    crops_dataset, batch_size=16, shuffle=False, sampler=None,\n","    batch_sampler=None, num_workers=4, pin_memory=True, drop_last=False\n",")\n","\n","\n","predictions = []\n","for batch in tqdm(crops_dataloader, total=len(crops_dataloader)):\n","    inputs = batch['img'].to(device)\n","    with torch.set_grad_enabled(False):\n","        outputs = model(inputs)\n","        # outputs = np.asarray(outputs.flatten().cpu())\n","        predictions.extend(outputs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxUUEiNVXyVT","executionInfo":{"status":"ok","timestamp":1655734413978,"user_tz":-120,"elapsed":11732,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}},"outputId":"1d1a43c7-5935-4830-8f6f-85710c929ed0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:10<00:00,  2.18s/it]\n"]}]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"ZrciWO2_ol8H","executionInfo":{"status":"error","timestamp":1655733263537,"user_tz":-120,"elapsed":2833,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}},"outputId":"075a4b8c-48ca-4077-ab51-b3ae9148c5eb"},"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/62 [00:01<?, ?it/s]\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-6068d4378e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimg_crops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImgCropsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_breast_fraction_patch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mimg_croped_patches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_crops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# pred_results = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# for i in range(len(img_crops_images)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-6068d4378e09>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimg_crops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImgCropsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_breast_fraction_patch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mimg_croped_patches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_crops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# pred_results = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# for i in range(len(img_crops_images)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to'"]}],"source":["tps = []\n","fps = []\n","fns = []\n","ignoreds = []\n","\n","for idx in tqdm(range(len(full_imgs_db))):\n","    img = full_imgs_db[idx]['img']\n","    lesion_bboxes = full_imgs_db[idx]['lesion_bboxes']\n","    img_id = full_imgs_db[idx]['img_id']\n","    lesion_mask = full_imgs_db[idx]['lesion_mask']\n","\n","    # img_crops = [x for x in ImgCropsDataset(img, 224, 100, 0.5)]\n","\n","    img_crops = list(ImgCropsDataset(img, patch_size=224, stride=224, min_breast_fraction_patch=0.5))\n","    img_croped_patches = [x['img'].to(device) for x in img_crops]\n","    # pred_results = []\n","    # for i in range(len(img_crops_images)):\n","    with torch.no_grad():\n","        pred_results = model(img_croped_patches)\n","\n","    patch_locations = [x['location'] for x in img_crops]\n","\n","\n","    rsc_candidates = np.concatenate([rescale_prediced_bboxes(x,y) for x,y in zip(pred_results, patch_locations) if rescale_prediced_bboxes(x,y)])\n","\n","    tp, fp, fn, ignored = get_tp_fp_fn_center_patch_criteria(rsc_candidates, lesion_mask, None, 14, True, scores_passed=True)\n","    \n","    tp['img_id'] = img_id\n","    fp['img_id'] = img_id\n","    fn['img_id'] = img_id\n","    ignored['img_id'] = img_id\n","    tps.append(tp)\n","    fps.append(fp)\n","    fns.append(fn)\n","    ignoreds.append(ignored)"]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"4CXuM9659_zU","executionInfo":{"status":"aborted","timestamp":1655732712573,"user_tz":-120,"elapsed":407,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_features = pd.concat(tps + fps)\n","fns_df = pd.concat(fns)\n","ignoreds_df = pd.concat(ignoreds)"],"metadata":{"id":"XEeoJXvQ7Bx2","executionInfo":{"status":"aborted","timestamp":1655732712574,"user_tz":-120,"elapsed":408,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_features['candidate_coordinates'] = [[r['x'] , r['y'] , r['radius']] for idx, r in test_features.iterrows()]\n","test_features['label'] = test_features.label == 'TP'\n","test_features.head()"],"metadata":{"id":"bGyyAwbH6f36","executionInfo":{"status":"aborted","timestamp":1655732712574,"user_tz":-120,"elapsed":408,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cEWADkSCol8L","executionInfo":{"status":"aborted","timestamp":1655732712575,"user_tz":-120,"elapsed":408,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"outputs":[],"source":["normal_imgs_ids = full_imgs_db.get_normal_imgs_ids()\n","\n","\n","froc_df_1st = get_froc_df_of_many_imgs_features(\n","    test_features[['candidate_coordinates', 'label', 'img_id', 'matching_gt', 'repeted_idxs']],\n","    fns_df,\n","    test_features.score.values,\n","    normal_imgs_ids\n",")\n","\n","sens1, avgs_fp_per_image1, _ = froc_curve(froc_df_1st, non_max_supression=True, cut_on_50fpi=True)\n"]},{"cell_type":"code","source":["from general_utils.plots import plot_froc"],"metadata":{"id":"5ykTDGmRC7D4","executionInfo":{"status":"aborted","timestamp":1655732712575,"user_tz":-120,"elapsed":408,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axs = plt.subplots(1, 1, figsize=(15, 10))\n","plot_froc(avgs_fp_per_image1, sens1, title='FROC DL', cut_on_50fpi=True, ax=axs)\n","\n"],"metadata":{"id":"-Uqcldw83iFG","executionInfo":{"status":"aborted","timestamp":1655732712575,"user_tz":-120,"elapsed":408,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"YkdR7PVYC52i","executionInfo":{"status":"aborted","timestamp":1655732712576,"user_tz":-120,"elapsed":409,"user":{"displayName":"Vladyslav Zalevskyi","userId":"16328735388891147587"}}},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 ('calc_det')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"d785cc99391f1decae0a31664a2bc430e1bb802c6f8076d9d1b38f05ab7f6160"}},"colab":{"name":"testDL_Detector.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}