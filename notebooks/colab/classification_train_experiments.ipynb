{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6776,"status":"ok","timestamp":1655757599480,"user":{"displayName":"JoaquÃ­n Seia","userId":"08240948874484507233"},"user_tz":-120},"id":"CTMQEfPg3-Dp","outputId":"196e458f-8c33-4e78-cfa8-ac33abd2499d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","from pathlib import Path\n","import os\n","repo_path = Path.cwd()/'drive/MyDrive/calcification_detection/calc-det/notebooks/'\n","os.chdir(str(repo_path))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5rnGeXT3-Du"},"outputs":[],"source":["!cp -r /content/drive/MyDrive/calcification_detection/data_rois/rois_centered_method/data_rois_128.zip /home/data_rois.zip\n","!unzip /home/data_rois.zip -d /home\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IpFDNhgd3-Dw"},"outputs":[],"source":["from pathlib import Path\n","thispath = Path.cwd().resolve()\n","import yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WDjU1gIRG-1I"},"outputs":[],"source":["# This code is an adapted version of Pytorch's ResNet Implementation\n","import torch\n","import numpy as np\n","\n","from collections import OrderedDict\n","from typing import Type, Callable, Union, List, Optional\n","from torch import Tensor, nn\n","\n","\n","def conv3x3(\n","    in_planes: int, out_planes: int, stride: int = 1,\n","    groups: int = 1, dilation: int = 1\n","):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(\n","        in_planes, out_planes, kernel_size=3, stride=stride,\n","        padding=dilation, groups=groups, bias=False, dilation=dilation\n","    )\n","\n","\n","def conv1x1(in_planes: int, out_planes: int, stride: int = 1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(\n","        in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion: int = 1\n","    \n","    def __init__(\n","        self, inplanes: int, planes: int, stride: int = 1,\n","        downsample: Optional[nn.Module] = None, groups: int = 1,\n","        base_width: int = 64, dilation: int = 1,\n","        norm_layer: Optional[Callable[..., nn.Module]] = None,\n","        act_fn: Optional[Callable[..., nn.Module]] = None,\n","        use_middle_act: bool = True\n","    ):\n","        super().__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if groups != 1 or base_width != 64:\n","            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n","        if dilation > 1:\n","            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n","        if act_fn is None:\n","            act_fn = nn.ReLU\n","\n","        self.use_middle_activation = use_middle_act\n","\n","        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = norm_layer(planes)\n","        self.act_fn = act_fn()\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x: Tensor):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        if self.use_middle_activation:\n","            out = self.act_fn(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.act_fn(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion: int = 4\n","\n","    def __init__(\n","        self,\n","        inplanes: int, planes: int, stride: int = 1,\n","        downsample: Optional[nn.Module] = None, groups: int = 1,\n","        base_width: int = 64, dilation: int = 1,\n","        norm_layer: Optional[Callable[..., nn.Module]] = None,\n","        act_fn: Optional[Callable[..., nn.Module]] = None\n","    ):\n","        super().__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if act_fn is None:\n","            act_fn = nn.ReLU\n","        width = int(planes * (base_width / 64.0)) * groups\n","\n","        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv1x1(inplanes, width)\n","        self.bn1 = norm_layer(width)\n","        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n","        self.bn2 = norm_layer(width)\n","        self.conv3 = conv1x1(width, planes * self.expansion)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","        self.act_fn = act_fn()\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.act_fn(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.act_fn(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.act_fn(out)\n","\n","        return out\n","\n","\n","class ResNetBased(nn.Module):\n","    def __init__(\n","        self,\n","        block: str = 'basic',\n","        # layers: List[int],\n","        num_classes: int = 1,\n","        zero_init_residual: bool = False,\n","        groups: int = 1,\n","        width_per_group: int = 64,\n","        replace_stride_with_dilation: Optional[List[bool]] = None,\n","        norm_layer: Optional[Callable[..., nn.Module]] = None,\n","        inplanes: int = 64,\n","        act_fn: Optional[Callable[..., nn.Module]] = None,\n","        downsample_blocks: int = 3,\n","        fc_dims: np.ndarray = None,\n","        dropout: float = 0,\n","        use_middle_act: bool = True,\n","        block_act: Optional[Callable[..., nn.Module]] = None\n","    ):\n","        super().__init__()\n","\n","        if block == 'basic':\n","            block = BasicBlock\n","        else:\n","            block = Bottleneck\n","\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer\n","        self.use_middle_act = use_middle_act\n","\n","        if act_fn is None:\n","            act_fn = nn.ReLU\n","        if block_act is None:\n","            block_act = nn.ReLU\n","        self.block_act = block_act\n","\n","        self.inplanes = inplanes\n","        self.dilation = 1\n","        if replace_stride_with_dilation is None:\n","            replace_stride_with_dilation = [False, False, False]\n","        if len(replace_stride_with_dilation) != 3:\n","            raise ValueError(\n","                \"replace_stride_with_dilation should be None \"\n","                f\"or a 3-element tuple, got {replace_stride_with_dilation}\"\n","            )\n","\n","        self.groups = groups\n","        self.base_width = width_per_group\n","        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.act_fn = act_fn\n","\n","        self.inner_layers = []\n","        out_planes = self.inplanes\n","        for i in range(downsample_blocks):\n","            if i == 0:\n","                self.inner_layers.append(\n","                    (f'layer{i+1}', self._make_layer(block, out_planes * 2, 2))\n","                )\n","            else:\n","                self.inner_layers.append(\n","                    (f'layer{i+1}',\n","                     self._make_layer(\n","                        block, out_planes * 2, 2, stride=2,\n","                        dilate=replace_stride_with_dilation[0])))\n","            out_planes = out_planes * 2\n","\n","        self.inner_layers = nn.Sequential(OrderedDict(self.inner_layers))\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","        self.in_features = out_planes\n","        if fc_dims is not None:\n","            layers_list = []\n","            for i in range(len(fc_dims)):\n","                in_neurons = self.in_features if i == 0 else fc_dims[i-1]\n","                layers_list = layers_list + [\n","                    (f'do{i+1}', nn.Dropout(dropout)),\n","                    (f'fc{i+1}', nn.Linear(in_neurons, fc_dims[i])),\n","                    (f'act{i+1}', self.act_fn())]\n","            layers_list.append((f'fc{i+2}', nn.Linear(fc_dims[i], 1)))\n","            self.classifier = nn.Sequential(OrderedDict(layers_list))\n","        else:\n","            self.classifier = nn.Sequential(OrderedDict([\n","                ('do', nn.Dropout(dropout)),\n","                ('fc', nn.Linear(self.in_features, num_classes))\n","            ]))\n","\n","        if isinstance(act_fn, nn.LeakyReLU):\n","            nl = 'leaky_relu'\n","        else:\n","            nl = 'relu'\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=nl)\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.kaiming_normal_(m.weight.data)\n","                nn.init.constant_(m.bias.data, 0)\n","\n","    def _make_layer(\n","        self, block: Type[Union[BasicBlock, Bottleneck]], planes: int,\n","        blocks: int, stride: int = 1, dilate: bool = False,\n","    ):\n","        norm_layer = self._norm_layer\n","        downsample = None\n","        previous_dilation = self.dilation\n","\n","        # Here we decide whether to use dilation convs or strides convs\n","        if dilate:\n","            self.dilation *= stride\n","            stride = 1\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                norm_layer(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(\n","            block(\n","                self.inplanes, planes, stride, downsample, self.groups,\n","                self.base_width, previous_dilation, norm_layer,\n","                act_fn=self.block_act, use_middle_act=self.use_middle_act\n","            )\n","        )\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(\n","                block(\n","                    self.inplanes,\n","                    planes,\n","                    groups=self.groups,\n","                    base_width=self.base_width,\n","                    dilation=self.dilation,\n","                    norm_layer=norm_layer,\n","                    act_fn=self.block_act,\n","                    use_middle_act=self.use_middle_act\n","                )\n","            )\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.act_fn()(x)\n","        x = self.inner_layers(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_dnS6dRL3-D5"},"outputs":[],"source":["from pathlib import Path\n","thispath = Path.cwd().resolve()\n","import sys; sys.path.insert(0, str(thispath.parent))\n","\n","from deep_learning.dataset.dataset import INBreast_Dataset_pytorch\n","from deep_learning.classification_models.models.base_classifier import CNNClasssifier\n","from deep_learning.classification_models.models.resnet_based_classifier import ResNetBased\n","import deep_learning.dl_utils as dl_utils\n","\n","import logging\n","import torch\n","import time\n","import random\n","import yaml\n","\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm import tqdm\n","from transformers import SwinForImageClassification\n","\n","logging.basicConfig(level=logging.INFO)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","def identity_function(arg):\n","    return arg\n","\n","\n","def train_model(datasets, dataloaders, data_transforms, model, criterion, optimizer, scheduler, cfg):\n","\n","    # guarantee reproducibility\n","    since = time.time()\n","    random.seed(0)\n","    torch.manual_seed(1442)\n","    np.random.seed(0)\n","\n","    # holders for best model\n","    best_metric = 0.0\n","    best_epoch = 0\n","    best_avgpr = 0\n","    best_f1 = 0\n","    last_three_losses = []\n","    early_stopping_count = 0\n","    previous_metric = 0\n","    previous_mean_loss = 0\n","    best_metric_name = cfg['training']['best_metric']\n","\n","    exp_path = Path.cwd().parent.parent/f'data/deepl_runs/{cfg[\"experiment_name\"]}'\n","    exp_path.mkdir(exist_ok=True, parents=True)\n","    best_model_path = exp_path / f'{cfg[\"experiment_name\"]}_{best_metric_name}.pt'\n","    best_model_path_auroc = exp_path / f'{cfg[\"experiment_name\"]}_auroc.pt'\n","    chkpt_path = exp_path / f'{cfg[\"experiment_name\"]}_chkpt.pt'\n","    logging.info(f'Storing experiment in: {exp_path}')\n","\n","    if cfg['training']['resume_training']:\n","        checkpoint = torch.load(chkpt_path)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        init_epoch = checkpoint['epoch'] + 1\n","    else:\n","        init_epoch = 0\n","\n","    # tensorboard loggs\n","    log_dir = exp_path/'tensorboard'\n","    log_dir.mkdir(exist_ok=True, parents=True)\n","    writer = SummaryWriter(log_dir=log_dir)\n","\n","    for epoch in range(init_epoch, cfg['training']['n_epochs']):\n","        logging.info(f'Epoch {epoch+1}/{cfg[\"training\"][\"n_epochs\"]}')\n","        logging.info(('-' * 10))\n","\n","        # resample used negatives to use the large diversity of them that we have\n","        datasets['train'].update_sample_used(epoch)\n","        dataloaders['train'] = DataLoader(\n","            datasets['train'], batch_size=cfg['dataloaders']['train_batch_size'],\n","            shuffle=True, num_workers=4, drop_last=False)\n","\n","        for phase in ['train', 'val']:\n","            # Set model to the corresponding mode and update lr if necessary\n","            if phase == 'train':\n","                if epoch != 0:\n","                    if cfg['training']['lr_scheduler'] == 'ReduceLROnPlateau':\n","                        scheduler.step(previous_loss)\n","                    else:\n","                        scheduler.step()\n","                writer.add_scalar(f\"LearningRate/{phase}\", optimizer.param_groups[0]['lr'], epoch)\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            # define holders for losses, preds and labels\n","            running_loss = 0.0\n","            epoch_preds, epoch_labels = [], []\n","\n","            # Iterate over data.\n","            if (cfg['training']['max_iters_per_epoch'] is not None) and (phase == 'train'):\n","                total_its = cfg['training']['max_iters_per_epoch']\n","            else:\n","                total_its = len(dataloaders[phase])\n","\n","            for it, sample in tqdm(enumerate(dataloaders[phase]), total=total_its):\n","                # Apply transformations and send to device\n","                sample['img'] = data_transforms[phase](sample['img'])\n","                inputs = sample['img'].to(device)\n","                labels = sample['label'].to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward pass (track history if only in train)\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # predict\n","                    outputs = model(inputs)\n","                    \n","                    if 'transformer' in cfg['model']['backbone']:\n","                        outputs = outputs['logits']\n","                    # store values\n","                    epoch_preds.append(np.asarray(\n","                        torch.sigmoid(outputs.detach()).flatten().cpu()))\n","                    epoch_labels.append(np.asarray(labels.detach().cpu()))\n","\n","                    # finish the comp. graph\n","                    loss = criterion(outputs.flatten(), labels.float())\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # once in a while store the images batch to check\n","                # if it in [100]:\n","                #     imgs = T.functional.rgb_to_grayscale(sample['img']).cpu()\n","                #     writer.add_images(f'Images/{phase}', imgs, epoch)\n","                #     del imgs\n","\n","                # get the epoch loss cumulatively\n","                running_loss += loss.item() * inputs.size(0)\n","\n","                if phase == 'train':\n","                    if (it != 0) and ((it % cfg['training']['log_iters']) == 0):\n","                        # compute and log the metrics for the iteration\n","                        iter_preds = np.concatenate(epoch_preds)\n","                        iter_labels = np.concatenate(epoch_labels)\n","                        iter_loss = running_loss / len(iter_preds)\n","                        iter_metrics = dl_utils.get_metrics(iter_labels, iter_preds)\n","                        dl_utils.tensorboard_logs(\n","                            writer, iter_loss, it+(total_its*epoch), iter_metrics, phase, True)\n","                    if cfg['training']['max_iters_per_epoch'] is not None:\n","                        if it == cfg['training']['max_iters_per_epoch']:\n","                            break\n","\n","            # compute and log the metrics for the epoch\n","            epoch_preds = np.concatenate(epoch_preds)\n","            epoch_labels = np.concatenate(epoch_labels)\n","            epoch_loss = running_loss / len(epoch_preds)\n","            last_three_losses.append(epoch_loss)\n","            if len(last_three_losses) > 3:\n","                last_three_losses = last_three_losses[1:]\n","            metrics = dl_utils.get_metrics(epoch_labels, epoch_preds)\n","            dl_utils.tensorboard_logs(writer, epoch_loss, epoch, metrics, phase)\n","\n","            # print status\n","            epoch_f1 = metrics['f1_score']\n","            message = f'{phase} Loss: {epoch_loss:.4f} Acc: {metrics[\"accuracy\"]:.4f}' \\\n","                      f' F1: {epoch_f1:.4f} AUROC: {metrics[\"auroc\"]:.4f} AvgPR: {metrics[\"avgpr\"]:.4f}'  \n","            logging.info(message)\n","\n","            # save last and best checkpoint\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'loss': loss}, chkpt_path)\n","\n","            if phase == 'val':\n","                if metrics[best_metric_name] > best_metric:\n","                    best_metric = metrics[best_metric_name]\n","                    best_f1 = epoch_f1\n","                    best_epoch = epoch+1\n","                    best_avgpr = metrics['avgpr']\n","                    best_threshold = metrics['threshold']\n","                    torch.save({\n","                        'model_state_dict': model.state_dict(),\n","                        'metrics': metrics,\n","                        'configuration': cfg\n","                        }, best_model_path)\n","\n","                if cfg['training']['early_stopping'] and (epoch != 0):\n","                    diff = np.mean(last_three_losses) - previous_mean_loss\n","                    if -diff < cfg['training']['early_stopping_args']['min_diff']:\n","                        early_stopping_count += 1\n","                    else:\n","                        early_stopping_count = 0\n","                previous_mean_loss = np.mean(last_three_losses)\n","                previous_metric = metrics[best_metric_name]\n","\n","        if cfg['training']['early_stopping']:\n","            max_epochs = cfg['training']['early_stopping_args']['max_epoch']\n","            if early_stopping_count == max_epochs:\n","                msg = f'Early stopping after {max_epochs} epochs without' \\\n","                    f' significant change in val metric'\n","                logging.info(msg)\n","                break\n","        logging.info(('-' * 10))\n","\n","    time_elapsed = time.time() - since\n","    message = f'Training complete in {(time_elapsed // 60):.0f}m ' \\\n","        f'{(time_elapsed % 60):.0f}s'\n","    logging.info(message)\n","    logging.info(f'Best val {best_metric_name}: {best_metric:4f}, avgPR {best_avgpr:.4f},' \\\n","                 f'threshold {best_threshold:.4f}, f1 {best_f1:.4f}, epoch {best_epoch}')\n","\n","    # close the tensorboard session\n","    writer.flush()\n","    writer.close()\n","\n","    # load best model weights before returning\n","    best_model = torch.load(best_model_path)\n","    model.load_state_dict(best_model['model_state_dict'])\n","    return model\n","\n","\n","def main():\n","    # read the configuration file\n","    config_path = str(thispath.parent.parent/'calc-det/deep_learning/config.yml')\n","    with open(config_path, \"r\") as ymlfile:\n","        cfg = yaml.safe_load(ymlfile)\n","\n","    # use the configuration for the dataset\n","    dataset_arguments = cfg['dataset']\n","    dataset_arguments['patch_images_path'] = Path(dataset_arguments['patch_images_path'])\n","    datasets = {\n","        'train': INBreast_Dataset_pytorch(\n","            partitions=['train'], neg_to_pos_ratio=dataset_arguments['train_neg_to_pos_ratio'],\n","            balancing_seed=0, **dataset_arguments),\n","        'val': INBreast_Dataset_pytorch(\n","            partitions=['validation'], neg_to_pos_ratio=None, **dataset_arguments)\n","    }\n","\n","    # use the configuration for the dataloaders\n","    dataloaders = {\n","        'val': DataLoader(\n","            datasets['val'], batch_size=cfg['dataloaders']['val_batch_size'],\n","            num_workers=4, drop_last=False),\n","        'train': DataLoader(\n","            datasets['train'], batch_size=cfg['dataloaders']['train_batch_size'],\n","            shuffle=True, num_workers=4, drop_last=False)\n","    }\n","\n","    # use the configuration for the transformations\n","    transforms = nn.Sequential(\n","        T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0, hue=0),\n","        T.RandomAffine(\n","            degrees=(0, 20), translate=None, scale=None, shear=(1, 10, 1, 10),\n","            interpolation=T.InterpolationMode.BILINEAR, fill=0\n","        ),\n","        T.RandomPerspective(distortion_scale=0.2),\n","        T.RandomRotation(degrees=(0, 20)),\n","        T.RandomRotation(degrees=(90, 110)),\n","        T.RandomResizedCrop(\n","            size=(cfg['model']['img_size'], cfg['model']['img_size']),\n","            scale=(0.9, 1), ratio=(1, 1)),\n","        T.RandomAutocontrast(),\n","        T.RandomHorizontalFlip(),\n","        T.RandomVerticalFlip()\n","    )\n","    transforms = T.RandomApply(transforms=transforms, p=cfg['data_aug']['prob'])\n","    data_transforms = {\n","        'train': identity_function if (cfg['data_aug']['prob'] == 0) else transforms,\n","        'val': identity_function\n","    }\n","\n","    # model configs\n","    if cfg['model']['backbone'] == 'swin_transformer':\n","        model = SwinForImageClassification.from_pretrained(\n","            'microsoft/swin-tiny-patch4-window7-224',\n","            # num_labels=2,\n","            # id2label={str(0): 'normal', str(1): 'abnormal'},\n","            # label2id={'normal': str(0), 'abnormal': str(1)},\n","            num_labels=1,\n","            # id2label={str(1): 'abnormal'},\n","            # label2id={'abnormal': str(1)},\n","            ignore_mismatched_sizes = True,\n","        )\n","    elif cfg['model']['backbone'] == 'vanilla':\n","        model = VanillaCNN(\n","            dropout=cfg['model']['dropout'],\n","            activation=getattr(nn, cfg['model']['activation'])()\n","        )\n","    elif cfg['model']['backbone'] == 'net1':\n","        model = Net1(\n","            dropout=cfg['model']['dropout'],\n","            activation=getattr(nn, cfg['model']['activation'])(inplace=True),\n","            n_downsamples=cfg['model']['n_downsamples'],\n","            fc_dims=cfg['model']['fc_dims'],\n","            image_size=cfg['model']['img_size']\n","        )\n","    elif cfg['model']['backbone'] == 'net2':\n","        model = ResNetBased(\n","            block=cfg['model']['block'],\n","            replace_stride_with_dilation=cfg['model']['replace_stride_with_dilation'],\n","            inplanes=cfg['model']['inplanes'],\n","            act_fn=getattr(nn, cfg['model']['activation']),\n","            downsample_blocks=cfg['model']['n_downsamples'],\n","            fc_dims=cfg['model']['fc_dims'],\n","            dropout=cfg['model']['dropout'],\n","            use_middle_act=cfg['model']['use_middle_activation'],\n","            block_act=getattr(nn, cfg['model']['bloc_act']),\n","        )\n","    else:\n","        model = CNNClasssifier(\n","            activation=getattr(nn, cfg['model']['activation'])(),\n","            dropout=cfg['model']['dropout'],\n","            fc_dims=cfg['model']['fc_dims'],\n","            freeze_weights=cfg['model']['freeze_weights'],\n","            backbone=cfg['model']['backbone'],\n","            pretrained=cfg['model']['pretrained'],\n","        )\n","        model = model.model\n","    model = model.to(device)\n","\n","    # training configs\n","    criterion = getattr(nn, cfg['training']['criterion'])()\n","\n","    optimizer = getattr(optim, cfg['training']['optimizer'])\n","    optimizer = optimizer(model.parameters(), **cfg['training']['optimizer_args'])\n","\n","    scheduler = getattr(lr_scheduler, cfg['training']['lr_scheduler'])\n","    scheduler = scheduler(optimizer, **cfg['training']['lr_scheduler_args'])\n","\n","    # train the model\n","    train_model(datasets, dataloaders, data_transforms, model, criterion, optimizer, scheduler, cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"smPBxGVE3-D0"},"outputs":[],"source":["cfg = {\n","    'model': {\n","        'activation': 'LeakyReLU',\n","        'bloc_act': None,\n","        'use_middle_activation': True,\n","        'dropout': 0.4,\n","        'fc_dims': None,\n","        'freeze_weights': False,\n","        'backbone': 'net2',\n","        'pretrained': True,\n","        'n_downsamples': 3,\n","        'img_size': 32,\n","        'block': 'basic',\n","        'replace_stride_with_dilation': None,\n","        'inplanes': 64\n","    },\n","    'dataset': {\n","        'extract_patches': False,\n","        'delete_previous': False,\n","        'extract_patches_method': 'centered',\n","        'patch_size': 128,\n","        'crop_size': 32,\n","        'center_noise': 10,\n","        'stride': 64,\n","        'min_breast_fraction_roi': 0.7,\n","        'n_jobs': -1,\n","        'cropped_imgs': True,\n","        'ignore_diameter_px': 15,\n","        'patch_images_path': '/home/data_rois/',\n","        'train_neg_to_pos_ratio': 10,   # 2% is the original ratio, 37 max\n","        'get_lesion_bboxes': True,\n","        'for_detection_net': False,\n","        'normalization': 'z_score'\n","    },\n","    'dataloaders': {\n","        'train_batch_size': 128,\n","        'val_batch_size': 256\n","    },\n","    'data_aug': {\n","        'prob': 0\n","    },\n","    'training': {\n","        'criterion': 'BCEWithLogitsLoss',\n","        'optimizer': 'Adam',\n","        'optimizer_args': {\n","            'lr': 0.0001 #, 'momentum': 0.9\n","        },\n","        'lr_scheduler': 'StepLR',\n","        'lr_scheduler_args': {\n","            'step_size': 7, 'gamma': 0.1\n","        },\n","        'n_epochs': 30,\n","        'best_metric': 'f1_score',\n","        'resume_training': False,\n","        'early_stopping': True,\n","        'early_stopping_args':{\n","            'min_diff': 0.0001,\n","            'max_epoch': 3\n","        },\n","        'log_iters': 100,\n","        'max_iters_per_epoch': None\n","        },\n","    'experiment_name': '32_resnet_01'\n","}\n","\n","cfg_path = str(thispath.parent.parent/'calc-det/deep_learning/config.yml')\n","with open(cfg_path, 'w') as yaml_file:\n","    yaml.dump(cfg, yaml_file, default_flow_style=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2158453,"status":"ok","timestamp":1655751422062,"user":{"displayName":"JoaquÃ­n Seia","userId":"08240948874484507233"},"user_tz":-120},"id":"hMg8WtLhIo0F","outputId":"3d438540-dcee-4b1e-cf31-b3deb226fab2"},"outputs":[{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/calcification_detection/calc-det/deep_learning/dataset/dataset.py:51: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n","  return_lesions_mask=get_lesion_bboxes, max_lesion_diam_mm=None, use_muscle_mask=False\n","INFO:root:Storing experiment in: /content/drive/MyDrive/calcification_detection/data/deepl_runs/32_net2_03\n","INFO:root:Epoch 1/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.58it/s]\n","INFO:root:train Loss: 0.2171 Acc: 0.8002 F1: 0.3997 AUROC: 0.8482 AvgPR: 0.5722\n","100%|ââââââââââ| 205/205 [00:23<00:00,  8.54it/s]\n","INFO:root:val Loss: 0.3886 Acc: 0.8288 F1: 0.1050 AUROC: 0.9210 AvgPR: 0.1811\n","INFO:root:----------\n","INFO:root:Epoch 2/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.59it/s]\n","INFO:root:train Loss: 0.1483 Acc: 0.8980 F1: 0.5898 AUROC: 0.9257 AvgPR: 0.7653\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.39it/s]\n","INFO:root:val Loss: 0.0322 Acc: 0.9746 F1: 0.4438 AUROC: 0.9696 AvgPR: 0.7582\n","INFO:root:----------\n","INFO:root:Epoch 3/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.61it/s]\n","INFO:root:train Loss: 0.1243 Acc: 0.9116 F1: 0.6344 AUROC: 0.9496 AvgPR: 0.8224\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.52it/s]\n","INFO:root:val Loss: 0.0206 Acc: 0.9570 F1: 0.3369 AUROC: 0.9830 AvgPR: 0.8040\n","INFO:root:----------\n","INFO:root:Epoch 4/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:45<00:42,  5.68it/s]\n","INFO:root:train Loss: 0.1137 Acc: 0.9204 F1: 0.6612 AUROC: 0.9565 AvgPR: 0.8466\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.54it/s]\n","INFO:root:val Loss: 0.0232 Acc: 0.9323 F1: 0.2386 AUROC: 0.9720 AvgPR: 0.7320\n","INFO:root:----------\n","INFO:root:Epoch 5/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:45<00:42,  5.69it/s]\n","INFO:root:train Loss: 0.1063 Acc: 0.9267 F1: 0.6824 AUROC: 0.9629 AvgPR: 0.8623\n","100%|ââââââââââ| 205/205 [00:23<00:00,  8.57it/s]\n","INFO:root:val Loss: 0.0255 Acc: 0.9594 F1: 0.3391 AUROC: 0.9692 AvgPR: 0.7263\n","INFO:root:----------\n","INFO:root:Epoch 6/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.60it/s]\n","INFO:root:train Loss: 0.1168 Acc: 0.9148 F1: 0.6457 AUROC: 0.9541 AvgPR: 0.8389\n","100%|ââââââââââ| 205/205 [00:23<00:00,  8.56it/s]\n","INFO:root:val Loss: 0.0411 Acc: 0.9561 F1: 0.3257 AUROC: 0.9737 AvgPR: 0.6198\n","INFO:root:----------\n","INFO:root:Epoch 7/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.64it/s]\n","INFO:root:train Loss: 0.1054 Acc: 0.9263 F1: 0.6837 AUROC: 0.9633 AvgPR: 0.8642\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.54it/s]\n","INFO:root:val Loss: 0.0201 Acc: 0.9545 F1: 0.3253 AUROC: 0.9862 AvgPR: 0.8022\n","INFO:root:----------\n","INFO:root:Epoch 8/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.58it/s]\n","INFO:root:train Loss: 0.1041 Acc: 0.9110 F1: 0.6441 AUROC: 0.9654 AvgPR: 0.8649\n","100%|ââââââââââ| 205/205 [00:23<00:00,  8.56it/s]\n","INFO:root:val Loss: 0.0216 Acc: 0.9447 F1: 0.2819 AUROC: 0.9778 AvgPR: 0.7668\n","INFO:root:----------\n","INFO:root:Epoch 9/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.61it/s]\n","INFO:root:train Loss: 0.1012 Acc: 0.9030 F1: 0.6278 AUROC: 0.9677 AvgPR: 0.8706\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.53it/s]\n","INFO:root:val Loss: 0.6903 Acc: 0.7876 F1: 0.0895 AUROC: 0.9137 AvgPR: 0.1231\n","INFO:root:----------\n","INFO:root:Epoch 10/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.62it/s]\n","INFO:root:train Loss: 0.0961 Acc: 0.9341 F1: 0.7085 AUROC: 0.9710 AvgPR: 0.8810\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.54it/s]\n","INFO:root:val Loss: 0.0175 Acc: 0.9643 F1: 0.3810 AUROC: 0.9894 AvgPR: 0.8264\n","INFO:root:----------\n","INFO:root:Epoch 11/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.63it/s]\n","INFO:root:train Loss: 0.0915 Acc: 0.9227 F1: 0.6798 AUROC: 0.9722 AvgPR: 0.8912\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.50it/s]\n","INFO:root:val Loss: 0.0794 Acc: 0.9455 F1: 0.2712 AUROC: 0.9577 AvgPR: 0.3398\n","INFO:root:----------\n","INFO:root:Epoch 12/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.63it/s]\n","INFO:root:train Loss: 0.0957 Acc: 0.9256 F1: 0.6856 AUROC: 0.9707 AvgPR: 0.8828\n","100%|ââââââââââ| 205/205 [00:23<00:00,  8.54it/s]\n","INFO:root:val Loss: 0.2089 Acc: 0.8974 F1: 0.1640 AUROC: 0.9428 AvgPR: 0.2442\n","INFO:root:----------\n","INFO:root:Epoch 13/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.59it/s]\n","INFO:root:train Loss: 0.0959 Acc: 0.9254 F1: 0.6874 AUROC: 0.9721 AvgPR: 0.8814\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.41it/s]\n","INFO:root:val Loss: 0.0382 Acc: 0.9699 F1: 0.4182 AUROC: 0.9823 AvgPR: 0.6275\n","INFO:root:----------\n","INFO:root:Epoch 14/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.65it/s]\n","INFO:root:train Loss: 0.0892 Acc: 0.9316 F1: 0.7047 AUROC: 0.9750 AvgPR: 0.8951\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.50it/s]\n","INFO:root:val Loss: 0.1974 Acc: 0.9448 F1: 0.2710 AUROC: 0.9597 AvgPR: 0.2892\n","INFO:root:----------\n","INFO:root:Epoch 15/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.62it/s]\n","INFO:root:train Loss: 0.0888 Acc: 0.9310 F1: 0.7042 AUROC: 0.9744 AvgPR: 0.8969\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.50it/s]\n","INFO:root:val Loss: 0.2985 Acc: 0.9060 F1: 0.1760 AUROC: 0.9428 AvgPR: 0.2173\n","INFO:root:----------\n","INFO:root:Epoch 16/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.63it/s]\n","INFO:root:train Loss: 0.0902 Acc: 0.9408 F1: 0.7309 AUROC: 0.9744 AvgPR: 0.8936\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.52it/s]\n","INFO:root:val Loss: 0.2161 Acc: 0.9189 F1: 0.2021 AUROC: 0.9554 AvgPR: 0.2699\n","INFO:root:----------\n","INFO:root:Epoch 17/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.60it/s]\n","INFO:root:train Loss: 0.0914 Acc: 0.9436 F1: 0.7391 AUROC: 0.9737 AvgPR: 0.8909\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.53it/s]\n","INFO:root:val Loss: 0.2439 Acc: 0.9081 F1: 0.1811 AUROC: 0.9477 AvgPR: 0.2378\n","INFO:root:----------\n","INFO:root:Epoch 18/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.60it/s]\n","INFO:root:train Loss: 0.0940 Acc: 0.9284 F1: 0.6927 AUROC: 0.9717 AvgPR: 0.8860\n","100%|ââââââââââ| 205/205 [00:23<00:00,  8.56it/s]\n","INFO:root:val Loss: 0.0365 Acc: 0.9588 F1: 0.3404 AUROC: 0.9743 AvgPR: 0.5817\n","INFO:root:----------\n","INFO:root:Epoch 19/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.62it/s]\n","INFO:root:train Loss: 0.0919 Acc: 0.9156 F1: 0.6627 AUROC: 0.9728 AvgPR: 0.8896\n","100%|ââââââââââ| 205/205 [00:23<00:00,  8.54it/s]\n","INFO:root:val Loss: 0.0976 Acc: 0.9585 F1: 0.3274 AUROC: 0.9542 AvgPR: 0.3363\n","INFO:root:----------\n","INFO:root:Epoch 20/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.62it/s]\n","INFO:root:train Loss: 0.0894 Acc: 0.9382 F1: 0.7248 AUROC: 0.9743 AvgPR: 0.8959\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.40it/s]\n","INFO:root:val Loss: 0.1021 Acc: 0.9524 F1: 0.3027 AUROC: 0.9620 AvgPR: 0.3286\n","INFO:root:----------\n","INFO:root:Epoch 21/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.59it/s]\n","INFO:root:train Loss: 0.0925 Acc: 0.9281 F1: 0.6942 AUROC: 0.9726 AvgPR: 0.8892\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.51it/s]\n","INFO:root:val Loss: 0.0335 Acc: 0.9569 F1: 0.3311 AUROC: 0.9764 AvgPR: 0.6293\n","INFO:root:----------\n","INFO:root:Epoch 22/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.63it/s]\n","INFO:root:train Loss: 0.0886 Acc: 0.9376 F1: 0.7223 AUROC: 0.9759 AvgPR: 0.8955\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.53it/s]\n","INFO:root:val Loss: 0.1473 Acc: 0.9552 F1: 0.3173 AUROC: 0.9683 AvgPR: 0.3161\n","INFO:root:----------\n","INFO:root:Epoch 23/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.62it/s]\n","INFO:root:train Loss: 0.0882 Acc: 0.9266 F1: 0.6922 AUROC: 0.9763 AvgPR: 0.8967\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.52it/s]\n","INFO:root:val Loss: 0.0698 Acc: 0.9609 F1: 0.3531 AUROC: 0.9757 AvgPR: 0.4169\n","INFO:root:----------\n","INFO:root:Epoch 24/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.62it/s]\n","INFO:root:train Loss: 0.0850 Acc: 0.9406 F1: 0.7342 AUROC: 0.9771 AvgPR: 0.9042\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.53it/s]\n","INFO:root:val Loss: 0.1305 Acc: 0.9461 F1: 0.2749 AUROC: 0.9593 AvgPR: 0.3091\n","INFO:root:----------\n","INFO:root:Epoch 25/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.59it/s]\n","INFO:root:train Loss: 0.0905 Acc: 0.9267 F1: 0.6912 AUROC: 0.9749 AvgPR: 0.8919\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.50it/s]\n","INFO:root:val Loss: 0.2359 Acc: 0.9226 F1: 0.2017 AUROC: 0.9392 AvgPR: 0.2234\n","INFO:root:----------\n","INFO:root:Epoch 26/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.60it/s]\n","INFO:root:train Loss: 0.0898 Acc: 0.9287 F1: 0.6971 AUROC: 0.9744 AvgPR: 0.8939\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.49it/s]\n","INFO:root:val Loss: 0.0694 Acc: 0.9430 F1: 0.2692 AUROC: 0.9685 AvgPR: 0.3985\n","INFO:root:----------\n","INFO:root:Epoch 27/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.56it/s]\n","INFO:root:train Loss: 0.0977 Acc: 0.9228 F1: 0.6766 AUROC: 0.9687 AvgPR: 0.8791\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.41it/s]\n","INFO:root:val Loss: 0.4745 Acc: 0.8390 F1: 0.1101 AUROC: 0.9131 AvgPR: 0.1334\n","INFO:root:----------\n","INFO:root:Epoch 28/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.64it/s]\n","INFO:root:train Loss: 0.0876 Acc: 0.9338 F1: 0.7132 AUROC: 0.9754 AvgPR: 0.8995\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.50it/s]\n","INFO:root:val Loss: 0.0447 Acc: 0.9426 F1: 0.2761 AUROC: 0.9778 AvgPR: 0.5401\n","INFO:root:----------\n","INFO:root:Epoch 29/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.59it/s]\n","INFO:root:train Loss: 0.0981 Acc: 0.9126 F1: 0.6525 AUROC: 0.9694 AvgPR: 0.8777\n","100%|ââââââââââ| 205/205 [00:23<00:00,  8.55it/s]\n","INFO:root:val Loss: 0.1066 Acc: 0.9479 F1: 0.2848 AUROC: 0.9591 AvgPR: 0.3259\n","INFO:root:----------\n","INFO:root:Epoch 30/30\n","INFO:root:----------\n"," 52%|ââââââ    | 261/500 [00:46<00:42,  5.63it/s]\n","INFO:root:train Loss: 0.0880 Acc: 0.9367 F1: 0.7186 AUROC: 0.9755 AvgPR: 0.8968\n","100%|ââââââââââ| 205/205 [00:24<00:00,  8.49it/s]\n","INFO:root:val Loss: 0.0230 Acc: 0.9539 F1: 0.3171 AUROC: 0.9760 AvgPR: 0.7355\n","INFO:root:----------\n","INFO:root:Training complete in 35m 56s\n","INFO:root:Best val auroc: 0.989448, avgPR 0.8264,threshold 0.0171, f1 0.3810, epoch 10\n"]}],"source":["cfg['model']['activation'] = 'LeakyReLU'\n","cfg['model']['dropout'] = 0.4\n","cfg['model']['fc_dims'] = None\n","cfg['model']['backbone'] = 'net2'\n","cfg['model']['n_downsamples'] = 3\n","cfg['model']['img_size'] = 32\n","cfg['model']['block'] = 'basic'\n","cfg['model']['replace_stride_with_dilation'] = None\n","cfg['model']['inplanes'] = 64\n","cfg['dataset']['crop_size'] = 32\n","cfg['dataset']['train_neg_to_pos_ratio'] = 10\n","cfg['dataset']['normalization'] = 'z_score'\n","cfg['dataloaders']['train_batch_size'] = 128\n","cfg['data_aug']['prob'] = 0.5\n","cfg['training']['criterion'] = 'BCEWithLogitsLoss'\n","cfg['training']['optimizer'] = 'Adam'\n","cfg['training']['optimizer_args'] = {'lr': 0.0001}\n","cfg['training']['lr_scheduler'] = 'StepLR'\n","cfg['training']['lr_scheduler_args'] = {'step_size': 7, 'gamma': 0.1}\n","cfg['training']['n_epochs'] = 30\n","cfg['training']['early_stopping'] = True\n","cfg['training']['early_stopping_args'] = {'min_diff': 0.00001, 'max_epoch': 3}\n","cfg['training']['log_iters'] = 100\n","cfg['training']['best_metric'] = 'auroc'\n","cfg['training']['max_iters_per_epoch'] = 500\n","cfg['experiment_name'] = '32_net2_03'\n","cfg_path = str(thispath.parent.parent/'calc-det/deep_learning/config.yml')\n","with open(cfg_path, 'w') as yaml_file:\n","    yaml.dump(cfg, yaml_file, default_flow_style=False)\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"executionInfo":{"elapsed":15837,"status":"error","timestamp":1655759689042,"user":{"displayName":"JoaquÃ­n Seia","userId":"08240948874484507233"},"user_tz":-120},"id":"iw32mxixWVsR","outputId":"2bd0e0b1-ae98-4d05-e157-d4c6f8ffc8a4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/calcification_detection/calc-det/deep_learning/dataset/dataset.py:51: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n","  return_lesions_mask=get_lesion_bboxes, max_lesion_diam_mm=None, use_muscle_mask=False\n","INFO:root:Storing experiment in: /content/drive/MyDrive/calcification_detection/data/deepl_runs/32_net2_04\n","INFO:root:Epoch 1/30\n","INFO:root:----------\n"," 20%|ââ        | 59/300 [00:13<00:56,  4.29it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-6e9eb35bbe12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myaml_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaml_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_flow_style\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-f7f05c60bfba>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-f7f05c60bfba>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(datasets, dataloaders, data_transforms, model, criterion, optimizer, scheduler, cfg)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;31m# get the epoch loss cumulatively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["cfg['model']['activation'] = 'GELU'\n","cfg['model']['use_middle_activation'] = False\n","cfg['model']['dropout'] = 0.4\n","cfg['model']['fc_dims'] = None\n","cfg['model']['backbone'] = 'net2'\n","cfg['model']['n_downsamples'] = 3\n","cfg['model']['img_size'] = 32\n","cfg['model']['block'] = 'basic'\n","cfg['model']['replace_stride_with_dilation'] = None\n","cfg['model']['inplanes'] = 64\n","cfg['dataset']['crop_size'] = 32\n","cfg['dataset']['center_noise'] = 5\n","cfg['dataset']['train_neg_to_pos_ratio'] = None\n","cfg['dataset']['normalization'] = 'z_score'\n","cfg['dataloaders']['train_batch_size'] = 128\n","cfg['data_aug']['prob'] = 0\n","cfg['training']['criterion'] = 'BCEWithLogitsLoss'\n","cfg['training']['optimizer'] = 'Adam'\n","cfg['training']['optimizer_args'] = {'lr': 0.0001}\n","cfg['training']['lr_scheduler'] = 'StepLR'\n","cfg['training']['lr_scheduler_args'] = {'step_size': 7, 'gamma': 0.1}\n","cfg['training']['n_epochs'] = 30\n","cfg['training']['early_stopping'] = True\n","cfg['training']['early_stopping_args'] = {'min_diff': 0.0001, 'max_epoch': 3}\n","cfg['training']['log_iters'] = 100\n","cfg['training']['best_metric'] = 'auroc'\n","cfg['training']['max_iters_per_epoch'] = 300\n","cfg['experiment_name'] = '32_net2_04'\n","cfg_path = str(thispath.parent.parent/'calc-det/deep_learning/config.yml')\n","with open(cfg_path, 'w') as yaml_file:\n","    yaml.dump(cfg, yaml_file, default_flow_style=False)\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1328580,"status":"ok","timestamp":1655761027232,"user":{"displayName":"JoaquÃ­n Seia","userId":"08240948874484507233"},"user_tz":-120},"id":"W4eOQQiL9jLf","outputId":"ef8f1369-0784-414c-ab2b-9ddbbdc198c3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/calcification_detection/calc-det/deep_learning/dataset/dataset.py:51: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n","  return_lesions_mask=get_lesion_bboxes, max_lesion_diam_mm=None, use_muscle_mask=False\n","INFO:root:Storing experiment in: /content/drive/MyDrive/calcification_detection/data/deepl_runs/32_net2_05\n","INFO:root:Epoch 1/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:08<00:00,  4.35it/s]\n","INFO:root:train Loss: 0.0775 Acc: 0.8472 F1: 0.2129 AUROC: 0.8876 AvgPR: 0.5432\n","100%|ââââââââââ| 205/205 [00:25<00:00,  7.98it/s]\n","INFO:root:val Loss: 0.0275 Acc: 0.9413 F1: 0.2655 AUROC: 0.9692 AvgPR: 0.7364\n","INFO:root:----------\n","INFO:root:Epoch 2/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:11<00:00,  4.18it/s]\n","INFO:root:train Loss: 0.0364 Acc: 0.9660 F1: 0.5749 AUROC: 0.9732 AvgPR: 0.8384\n","100%|ââââââââââ| 205/205 [00:26<00:00,  7.73it/s]\n","INFO:root:val Loss: 0.0183 Acc: 0.9687 F1: 0.4122 AUROC: 0.9886 AvgPR: 0.8162\n","INFO:root:----------\n","INFO:root:Epoch 3/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:14<00:00,  4.04it/s]\n","INFO:root:train Loss: 0.0252 Acc: 0.9684 F1: 0.6082 AUROC: 0.9915 AvgPR: 0.9033\n","100%|ââââââââââ| 205/205 [00:26<00:00,  7.74it/s]\n","INFO:root:val Loss: 0.0186 Acc: 0.9746 F1: 0.4545 AUROC: 0.9818 AvgPR: 0.8177\n","INFO:root:----------\n","INFO:root:Epoch 4/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:14<00:00,  4.05it/s]\n","INFO:root:train Loss: 0.0246 Acc: 0.9661 F1: 0.5945 AUROC: 0.9873 AvgPR: 0.9126\n","100%|ââââââââââ| 205/205 [00:26<00:00,  7.64it/s]\n","INFO:root:val Loss: 0.0154 Acc: 0.9552 F1: 0.3345 AUROC: 0.9898 AvgPR: 0.8610\n","INFO:root:----------\n","INFO:root:Epoch 5/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:14<00:00,  4.05it/s]\n","INFO:root:train Loss: 0.0215 Acc: 0.9755 F1: 0.6841 AUROC: 0.9900 AvgPR: 0.9358\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.47it/s]\n","INFO:root:val Loss: 0.0147 Acc: 0.9675 F1: 0.4068 AUROC: 0.9880 AvgPR: 0.8627\n","INFO:root:----------\n","INFO:root:Epoch 6/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:14<00:00,  4.02it/s]\n","INFO:root:train Loss: 0.0185 Acc: 0.9691 F1: 0.6157 AUROC: 0.9931 AvgPR: 0.9414\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.34it/s]\n","INFO:root:val Loss: 0.0144 Acc: 0.9649 F1: 0.3865 AUROC: 0.9895 AvgPR: 0.8692\n","INFO:root:----------\n","INFO:root:Epoch 7/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:13<00:00,  4.06it/s]\n","INFO:root:train Loss: 0.0178 Acc: 0.9847 F1: 0.7675 AUROC: 0.9933 AvgPR: 0.9475\n","100%|ââââââââââ| 205/205 [00:26<00:00,  7.70it/s]\n","INFO:root:val Loss: 0.0183 Acc: 0.9772 F1: 0.4923 AUROC: 0.9891 AvgPR: 0.8751\n","INFO:root:----------\n","INFO:root:Epoch 8/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:14<00:00,  4.05it/s]\n","INFO:root:train Loss: 0.0139 Acc: 0.9817 F1: 0.7341 AUROC: 0.9947 AvgPR: 0.9643\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.52it/s]\n","INFO:root:val Loss: 0.0138 Acc: 0.9802 F1: 0.5271 AUROC: 0.9900 AvgPR: 0.8798\n","INFO:root:----------\n","INFO:root:Epoch 9/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:14<00:00,  4.02it/s]\n","INFO:root:train Loss: 0.0141 Acc: 0.9847 F1: 0.7752 AUROC: 0.9957 AvgPR: 0.9654\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.55it/s]\n","INFO:root:val Loss: 0.0128 Acc: 0.9816 F1: 0.5478 AUROC: 0.9914 AvgPR: 0.8931\n","INFO:root:----------\n","INFO:root:Epoch 10/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:14<00:00,  4.02it/s]\n","INFO:root:train Loss: 0.0123 Acc: 0.9843 F1: 0.7675 AUROC: 0.9973 AvgPR: 0.9721\n","100%|ââââââââââ| 205/205 [00:26<00:00,  7.70it/s]\n","INFO:root:val Loss: 0.0124 Acc: 0.9743 F1: 0.4663 AUROC: 0.9907 AvgPR: 0.8982\n","INFO:root:----------\n","INFO:root:Epoch 11/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:14<00:00,  4.05it/s]\n","INFO:root:train Loss: 0.0133 Acc: 0.9917 F1: 0.8603 AUROC: 0.9962 AvgPR: 0.9680\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.49it/s]\n","INFO:root:val Loss: 0.0133 Acc: 0.9684 F1: 0.4159 AUROC: 0.9912 AvgPR: 0.8881\n","INFO:root:----------\n","INFO:root:Epoch 12/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:14<00:00,  4.03it/s]\n","INFO:root:train Loss: 0.0131 Acc: 0.9814 F1: 0.7333 AUROC: 0.9969 AvgPR: 0.9672\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.54it/s]\n","INFO:root:val Loss: 0.0129 Acc: 0.9709 F1: 0.4360 AUROC: 0.9918 AvgPR: 0.8883\n","INFO:root:----------\n","INFO:root:Epoch 13/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:14<00:00,  4.02it/s]\n","INFO:root:train Loss: 0.0139 Acc: 0.9886 F1: 0.8179 AUROC: 0.9960 AvgPR: 0.9623\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.53it/s]\n","INFO:root:val Loss: 0.0131 Acc: 0.9750 F1: 0.4712 AUROC: 0.9916 AvgPR: 0.8892\n","INFO:root:Early stopping after 3 epochs without significant change in val metric\n","INFO:root:Training complete in 22m 7s\n","INFO:root:Best val auroc: 0.991839, avgPR 0.8883,threshold 0.0100, f1 0.4360, epoch 12\n"]}],"source":["cfg['model']['activation'] = 'GELU'\n","cfg['model']['use_middle_activation'] = False\n","cfg['model']['dropout'] = 0.4\n","cfg['model']['fc_dims'] = None\n","cfg['model']['backbone'] = 'net2'\n","cfg['model']['n_downsamples'] = 3\n","cfg['model']['img_size'] = 32\n","cfg['model']['block'] = 'basic'\n","cfg['model']['replace_stride_with_dilation'] = None\n","cfg['model']['inplanes'] = 64\n","cfg['dataset']['crop_size'] = 32\n","cfg['dataset']['center_noise'] = 5\n","cfg['dataset']['train_neg_to_pos_ratio'] = None\n","cfg['dataset']['normalization'] = 'z_score'\n","cfg['dataloaders']['train_batch_size'] = 128\n","cfg['data_aug']['prob'] = 0\n","cfg['training']['criterion'] = 'BCEWithLogitsLoss'\n","cfg['training']['optimizer'] = 'Adam'\n","cfg['training']['optimizer_args'] = {'lr': 0.0001}\n","cfg['training']['lr_scheduler'] = 'StepLR'\n","cfg['training']['lr_scheduler_args'] = {'step_size': 7, 'gamma': 0.1}\n","cfg['training']['n_epochs'] = 30\n","cfg['training']['early_stopping'] = True\n","cfg['training']['early_stopping_args'] = {'min_diff': 0.0001, 'max_epoch': 3}\n","cfg['training']['log_iters'] = 100\n","cfg['training']['best_metric'] = 'auroc'\n","cfg['training']['max_iters_per_epoch'] = 300\n","cfg['experiment_name'] = '32_net2_05'\n","cfg_path = str(thispath.parent.parent/'calc-det/deep_learning/config.yml')\n","with open(cfg_path, 'w') as yaml_file:\n","    yaml.dump(cfg, yaml_file, default_flow_style=False)\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1574438,"status":"ok","timestamp":1655762613439,"user":{"displayName":"JoaquÃ­n Seia","userId":"08240948874484507233"},"user_tz":-120},"id":"jfYoIGa583Dw","outputId":"9b88ceb1-692c-489d-a83c-2f0b2d993c4f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/calcification_detection/calc-det/deep_learning/dataset/dataset.py:51: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n","  return_lesions_mask=get_lesion_bboxes, max_lesion_diam_mm=None, use_muscle_mask=False\n","INFO:root:Storing experiment in: /content/drive/MyDrive/calcification_detection/data/deepl_runs/32_net2_05\n","INFO:root:Epoch 1/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:16<00:00,  3.94it/s]\n","INFO:root:train Loss: 0.0707 Acc: 0.8623 F1: 0.2413 AUROC: 0.9150 AvgPR: 0.6092\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.46it/s]\n","INFO:root:val Loss: 0.0235 Acc: 0.9701 F1: 0.4120 AUROC: 0.9749 AvgPR: 0.7813\n","INFO:root:----------\n","INFO:root:Epoch 2/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.96it/s]\n","INFO:root:train Loss: 0.0299 Acc: 0.9724 F1: 0.6323 AUROC: 0.9825 AvgPR: 0.8802\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.40it/s]\n","INFO:root:val Loss: 0.0191 Acc: 0.9710 F1: 0.4299 AUROC: 0.9887 AvgPR: 0.8380\n","INFO:root:----------\n","INFO:root:Epoch 3/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.95it/s]\n","INFO:root:train Loss: 0.0228 Acc: 0.9723 F1: 0.6396 AUROC: 0.9914 AvgPR: 0.9194\n","100%|ââââââââââ| 205/205 [00:28<00:00,  7.29it/s]\n","INFO:root:val Loss: 0.0166 Acc: 0.9559 F1: 0.3368 AUROC: 0.9877 AvgPR: 0.8472\n","INFO:root:----------\n","INFO:root:Epoch 4/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.96it/s]\n","INFO:root:train Loss: 0.0226 Acc: 0.9745 F1: 0.6616 AUROC: 0.9889 AvgPR: 0.9225\n","100%|ââââââââââ| 205/205 [00:28<00:00,  7.30it/s]\n","INFO:root:val Loss: 0.0134 Acc: 0.9573 F1: 0.3455 AUROC: 0.9923 AvgPR: 0.8804\n","INFO:root:----------\n","INFO:root:Epoch 5/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.95it/s]\n","INFO:root:train Loss: 0.0192 Acc: 0.9850 F1: 0.7800 AUROC: 0.9903 AvgPR: 0.9456\n","100%|ââââââââââ| 205/205 [00:28<00:00,  7.32it/s]\n","INFO:root:val Loss: 0.0169 Acc: 0.9762 F1: 0.4747 AUROC: 0.9849 AvgPR: 0.8493\n","INFO:root:----------\n","INFO:root:Epoch 6/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.95it/s]\n","INFO:root:train Loss: 0.0158 Acc: 0.9783 F1: 0.6969 AUROC: 0.9934 AvgPR: 0.9562\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.35it/s]\n","INFO:root:val Loss: 0.0151 Acc: 0.9663 F1: 0.3977 AUROC: 0.9905 AvgPR: 0.8664\n","INFO:root:----------\n","INFO:root:Epoch 7/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.96it/s]\n","INFO:root:train Loss: 0.0156 Acc: 0.9833 F1: 0.7538 AUROC: 0.9964 AvgPR: 0.9563\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.40it/s]\n","INFO:root:val Loss: 0.0151 Acc: 0.9570 F1: 0.3436 AUROC: 0.9915 AvgPR: 0.8768\n","INFO:root:----------\n","INFO:root:Epoch 8/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.96it/s]\n","INFO:root:train Loss: 0.0131 Acc: 0.9827 F1: 0.7456 AUROC: 0.9946 AvgPR: 0.9672\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.37it/s]\n","INFO:root:val Loss: 0.0145 Acc: 0.9716 F1: 0.4379 AUROC: 0.9901 AvgPR: 0.8746\n","INFO:root:----------\n","INFO:root:Epoch 9/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.96it/s]\n","INFO:root:train Loss: 0.0134 Acc: 0.9861 F1: 0.7913 AUROC: 0.9962 AvgPR: 0.9683\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.37it/s]\n","INFO:root:val Loss: 0.0124 Acc: 0.9764 F1: 0.4867 AUROC: 0.9922 AvgPR: 0.8975\n","INFO:root:----------\n","INFO:root:Epoch 10/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.95it/s]\n","INFO:root:train Loss: 0.0109 Acc: 0.9891 F1: 0.8264 AUROC: 0.9976 AvgPR: 0.9771\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.38it/s]\n","INFO:root:val Loss: 0.0123 Acc: 0.9720 F1: 0.4450 AUROC: 0.9919 AvgPR: 0.8971\n","INFO:root:----------\n","INFO:root:Epoch 11/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.96it/s]\n","INFO:root:train Loss: 0.0121 Acc: 0.9923 F1: 0.8690 AUROC: 0.9962 AvgPR: 0.9725\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.52it/s]\n","INFO:root:val Loss: 0.0127 Acc: 0.9760 F1: 0.4808 AUROC: 0.9920 AvgPR: 0.8911\n","INFO:root:----------\n","INFO:root:Epoch 12/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.98it/s]\n","INFO:root:train Loss: 0.0110 Acc: 0.9887 F1: 0.8186 AUROC: 0.9973 AvgPR: 0.9752\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.54it/s]\n","INFO:root:val Loss: 0.0123 Acc: 0.9694 F1: 0.4251 AUROC: 0.9932 AvgPR: 0.8950\n","INFO:root:----------\n","INFO:root:Epoch 13/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.98it/s]\n","INFO:root:train Loss: 0.0122 Acc: 0.9922 F1: 0.8676 AUROC: 0.9965 AvgPR: 0.9687\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.51it/s]\n","INFO:root:val Loss: 0.0126 Acc: 0.9689 F1: 0.4205 AUROC: 0.9927 AvgPR: 0.8944\n","INFO:root:----------\n","INFO:root:Epoch 14/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.98it/s]\n","INFO:root:train Loss: 0.0112 Acc: 0.9900 F1: 0.8382 AUROC: 0.9973 AvgPR: 0.9756\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.50it/s]\n","INFO:root:val Loss: 0.0148 Acc: 0.9732 F1: 0.4508 AUROC: 0.9893 AvgPR: 0.8663\n","INFO:root:----------\n","INFO:root:Epoch 15/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.98it/s]\n","INFO:root:train Loss: 0.0110 Acc: 0.9918 F1: 0.8624 AUROC: 0.9981 AvgPR: 0.9751\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.45it/s]\n","INFO:root:val Loss: 0.0135 Acc: 0.9756 F1: 0.4788 AUROC: 0.9912 AvgPR: 0.8842\n","INFO:root:Early stopping after 3 epochs without significant change in val metric\n","INFO:root:Training complete in 26m 13s\n","INFO:root:Best val auroc: 0.993204, avgPR 0.8950,threshold 0.0070, f1 0.4251, epoch 12\n"]}],"source":["cfg['model']['activation'] = 'GELU'\n","cfg['model']['use_middle_activation'] = True\n","cfg['model']['dropout'] = 0.4\n","cfg['model']['fc_dims'] = None\n","cfg['model']['backbone'] = 'net2'\n","cfg['model']['n_downsamples'] = 3\n","cfg['model']['img_size'] = 32\n","cfg['model']['block'] = 'basic'\n","cfg['model']['replace_stride_with_dilation'] = None\n","cfg['model']['inplanes'] = 64\n","cfg['dataset']['crop_size'] = 32\n","cfg['dataset']['center_noise'] = 5\n","cfg['dataset']['train_neg_to_pos_ratio'] = None\n","cfg['dataset']['normalization'] = 'z_score'\n","cfg['dataloaders']['train_batch_size'] = 128\n","cfg['data_aug']['prob'] = 0\n","cfg['training']['criterion'] = 'BCEWithLogitsLoss'\n","cfg['training']['optimizer'] = 'Adam'\n","cfg['training']['optimizer_args'] = {'lr': 0.0001}\n","cfg['training']['lr_scheduler'] = 'StepLR'\n","cfg['training']['lr_scheduler_args'] = {'step_size': 7, 'gamma': 0.1}\n","cfg['training']['n_epochs'] = 30\n","cfg['training']['early_stopping'] = True\n","cfg['training']['early_stopping_args'] = {'min_diff': 0.0001, 'max_epoch': 3}\n","cfg['training']['log_iters'] = 100\n","cfg['training']['best_metric'] = 'auroc'\n","cfg['training']['max_iters_per_epoch'] = 300\n","cfg['experiment_name'] = '32_net2_05'\n","cfg_path = str(thispath.parent.parent/'calc-det/deep_learning/config.yml')\n","with open(cfg_path, 'w') as yaml_file:\n","    yaml.dump(cfg, yaml_file, default_flow_style=False)\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1354149,"status":"ok","timestamp":1655763969581,"user":{"displayName":"JoaquÃ­n Seia","userId":"08240948874484507233"},"user_tz":-120},"id":"rOqlhvkL10c1","outputId":"4559cce8-2969-4bef-d183-f06f5050282e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/calcification_detection/calc-det/deep_learning/dataset/dataset.py:51: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n","  return_lesions_mask=get_lesion_bboxes, max_lesion_diam_mm=None, use_muscle_mask=False\n","INFO:root:Storing experiment in: /content/drive/MyDrive/calcification_detection/data/deepl_runs/32_net2_06\n","INFO:root:Epoch 1/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.98it/s]\n","INFO:root:train Loss: 0.0776 Acc: 0.8686 F1: 0.2409 AUROC: 0.9044 AvgPR: 0.5598\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.54it/s]\n","INFO:root:val Loss: 0.0227 Acc: 0.9576 F1: 0.3398 AUROC: 0.9800 AvgPR: 0.7725\n","INFO:root:----------\n","INFO:root:Epoch 2/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.99it/s]\n","INFO:root:train Loss: 0.0320 Acc: 0.9560 F1: 0.5205 AUROC: 0.9807 AvgPR: 0.8661\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.54it/s]\n","INFO:root:val Loss: 0.0195 Acc: 0.9719 F1: 0.4352 AUROC: 0.9860 AvgPR: 0.8133\n","INFO:root:----------\n","INFO:root:Epoch 3/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.99it/s]\n","INFO:root:train Loss: 0.0246 Acc: 0.9694 F1: 0.6179 AUROC: 0.9885 AvgPR: 0.9146\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.55it/s]\n","INFO:root:val Loss: 0.0183 Acc: 0.9622 F1: 0.3654 AUROC: 0.9871 AvgPR: 0.8189\n","INFO:root:----------\n","INFO:root:Epoch 4/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.98it/s]\n","INFO:root:train Loss: 0.0252 Acc: 0.9770 F1: 0.6820 AUROC: 0.9870 AvgPR: 0.9113\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.55it/s]\n","INFO:root:val Loss: 0.0149 Acc: 0.9532 F1: 0.3234 AUROC: 0.9892 AvgPR: 0.8566\n","INFO:root:----------\n","INFO:root:Epoch 5/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.99it/s]\n","INFO:root:train Loss: 0.0216 Acc: 0.9821 F1: 0.7462 AUROC: 0.9877 AvgPR: 0.9355\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.56it/s]\n","INFO:root:val Loss: 0.0144 Acc: 0.9652 F1: 0.3910 AUROC: 0.9903 AvgPR: 0.8667\n","INFO:root:----------\n","INFO:root:Epoch 6/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.99it/s]\n","INFO:root:train Loss: 0.0168 Acc: 0.9821 F1: 0.7335 AUROC: 0.9933 AvgPR: 0.9505\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.53it/s]\n","INFO:root:val Loss: 0.0151 Acc: 0.9613 F1: 0.3643 AUROC: 0.9899 AvgPR: 0.8589\n","INFO:root:----------\n","INFO:root:Epoch 7/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.99it/s]\n","INFO:root:train Loss: 0.0165 Acc: 0.9731 F1: 0.6558 AUROC: 0.9942 AvgPR: 0.9523\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.50it/s]\n","INFO:root:val Loss: 0.0154 Acc: 0.9833 F1: 0.5661 AUROC: 0.9898 AvgPR: 0.8776\n","INFO:root:----------\n","INFO:root:Epoch 8/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.98it/s]\n","INFO:root:train Loss: 0.0134 Acc: 0.9858 F1: 0.7808 AUROC: 0.9946 AvgPR: 0.9666\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.52it/s]\n","INFO:root:val Loss: 0.0133 Acc: 0.9791 F1: 0.5170 AUROC: 0.9914 AvgPR: 0.8866\n","INFO:root:----------\n","INFO:root:Epoch 9/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.99it/s]\n","INFO:root:train Loss: 0.0133 Acc: 0.9845 F1: 0.7733 AUROC: 0.9955 AvgPR: 0.9692\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.43it/s]\n","INFO:root:val Loss: 0.0126 Acc: 0.9774 F1: 0.4972 AUROC: 0.9910 AvgPR: 0.8929\n","INFO:root:----------\n","INFO:root:Epoch 10/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.98it/s]\n","INFO:root:train Loss: 0.0112 Acc: 0.9877 F1: 0.8086 AUROC: 0.9972 AvgPR: 0.9756\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.57it/s]\n","INFO:root:val Loss: 0.0121 Acc: 0.9869 F1: 0.6269 AUROC: 0.9915 AvgPR: 0.9000\n","INFO:root:----------\n","INFO:root:Epoch 11/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.99it/s]\n","INFO:root:train Loss: 0.0125 Acc: 0.9878 F1: 0.8089 AUROC: 0.9957 AvgPR: 0.9713\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.53it/s]\n","INFO:root:val Loss: 0.0125 Acc: 0.9739 F1: 0.4623 AUROC: 0.9917 AvgPR: 0.8953\n","INFO:root:----------\n","INFO:root:Epoch 12/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.98it/s]\n","INFO:root:train Loss: 0.0117 Acc: 0.9875 F1: 0.8033 AUROC: 0.9975 AvgPR: 0.9725\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.58it/s]\n","INFO:root:val Loss: 0.0128 Acc: 0.9812 F1: 0.5406 AUROC: 0.9920 AvgPR: 0.8881\n","INFO:root:----------\n","INFO:root:Epoch 13/30\n","INFO:root:----------\n","100%|ââââââââââ| 300/300 [01:15<00:00,  3.98it/s]\n","INFO:root:train Loss: 0.0128 Acc: 0.9808 F1: 0.7297 AUROC: 0.9961 AvgPR: 0.9651\n","100%|ââââââââââ| 205/205 [00:27<00:00,  7.56it/s]\n","INFO:root:val Loss: 0.0128 Acc: 0.9742 F1: 0.4648 AUROC: 0.9920 AvgPR: 0.8922\n","INFO:root:Early stopping after 3 epochs without significant change in val metric\n","INFO:root:Training complete in 22m 32s\n","INFO:root:Best val auroc: 0.992018, avgPR 0.8881,threshold 0.0156, f1 0.5406, epoch 12\n"]}],"source":["cfg['model']['activation'] = 'GELU'\n","cfg['model']['bloc_act'] = 'GELU'\n","cfg['model']['use_middle_activation'] = True\n","cfg['model']['dropout'] = 0.4\n","cfg['model']['fc_dims'] = None\n","cfg['model']['backbone'] = 'net2'\n","cfg['model']['n_downsamples'] = 3\n","cfg['model']['img_size'] = 32\n","cfg['model']['block'] = 'basic'\n","cfg['model']['replace_stride_with_dilation'] = None\n","cfg['model']['inplanes'] = 64\n","cfg['dataset']['crop_size'] = 32\n","cfg['dataset']['center_noise'] = 5\n","cfg['dataset']['train_neg_to_pos_ratio'] = None\n","cfg['dataset']['normalization'] = 'z_score'\n","cfg['dataloaders']['train_batch_size'] = 128\n","cfg['data_aug']['prob'] = 0\n","cfg['training']['criterion'] = 'BCEWithLogitsLoss'\n","cfg['training']['optimizer'] = 'Adam'\n","cfg['training']['optimizer_args'] = {'lr': 0.0001}\n","cfg['training']['lr_scheduler'] = 'StepLR'\n","cfg['training']['lr_scheduler_args'] = {'step_size': 7, 'gamma': 0.1}\n","cfg['training']['n_epochs'] = 30\n","cfg['training']['early_stopping'] = True\n","cfg['training']['early_stopping_args'] = {'min_diff': 0.0001, 'max_epoch': 3}\n","cfg['training']['log_iters'] = 100\n","cfg['training']['best_metric'] = 'auroc'\n","cfg['training']['max_iters_per_epoch'] = 300\n","cfg['experiment_name'] = '32_net2_06'\n","cfg_path = str(thispath.parent.parent/'calc-det/deep_learning/config.yml')\n","with open(cfg_path, 'w') as yaml_file:\n","    yaml.dump(cfg, yaml_file, default_flow_style=False)\n","main()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"classification_train_experiments.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.13 ('calc_det')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f094a5cfaa0fb3b1e730adb1bd2a385aed1bdbc34460cd7c5bc1913497751e38"}}},"nbformat":4,"nbformat_minor":0}