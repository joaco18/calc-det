{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Face classification using Haar-like feature descriptor\n",
        "\n",
        "Haar-like feature descriptors were successfully used to implement the first\n",
        "real-time face detector [1]_. Inspired by this application, we propose an\n",
        "example illustrating the extraction, selection, and classification of Haar-like\n",
        "features to detect faces vs. non-faces.\n",
        "\n",
        "## Notes\n",
        "\n",
        "This example relies on `scikit-learn <https://scikit-learn.org/>`_ for feature\n",
        "selection and classification.\n",
        "\n",
        "## References\n",
        "\n",
        ".. [1] Viola, Paul, and Michael J. Jones. \"Robust real-time face\n",
        "       detection.\" International journal of computer vision 57.2\n",
        "       (2004): 137-154.\n",
        "       https://www.merl.com/publications/docs/TR2004-043.pdf\n",
        "       :DOI:`10.1109/CVPR.2001.990517`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The procedure to extract the Haar-like features from an image is relatively\n",
        "simple. Firstly, a region of interest (ROI) is defined. Secondly, the\n",
        "integral image within this ROI is computed. Finally, the integral image is\n",
        "used to extract the features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dask import delayed\n",
        "from skimage.transform import integral_image\n",
        "from skimage.feature import haar_like_feature\n",
        "from skimage.feature import haar_like_feature_coord\n",
        "from skimage.feature import draw_haar_like_feature\n",
        "\n",
        "@delayed\n",
        "def extract_feature_image(img, feature_type=None, feature_coord=None):\n",
        "    \"\"\"Extract the haar feature for the current image\"\"\"\n",
        "    ii = integral_image(img)\n",
        "    return haar_like_feature(ii, 0, 0, ii.shape[0], ii.shape[1],\n",
        "                             feature_type=feature_type,\n",
        "                             feature_coord=feature_coord)\n",
        "\n",
        "@delayed\n",
        "def extract_rot_feature_image(img, haarfe):\n",
        "    \"\"\"Extract the haar feature for the current image\"\"\"\n",
        "    return haarfe.extract_features_from_crop(img)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use a subset of CBCL dataset which is composed of 100 face images and\n",
        "100 non-face images. Each image has been resized to a ROI of 19 by 19\n",
        "pixels. We select 75 images from each group to train a classifier and\n",
        "determine the most salient features. The remaining 25 images from each\n",
        "class are used to assess the performance of the classifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "INFO:root:\n",
            "Unfortunately, your original traceback can not be constructed.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/home/jseia/anaconda3/envs/calc_det/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3361, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "  File \"pandas/_libs/index.pyx\", line 76, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'labels'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jseia/anaconda3/envs/calc_det/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipykernel_22094/3537809768.py\", line 40, in <module>\n",
            "    all_features['labels'].values, train_size=0.7,\n",
            "  File \"/home/jseia/anaconda3/envs/calc_det/lib/python3.9/site-packages/pandas/core/frame.py\", line 3458, in __getitem__\n",
            "    indexer = self.columns.get_loc(key)\n",
            "  File \"/home/jseia/anaconda3/envs/calc_det/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3363, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'labels'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jseia/anaconda3/envs/calc_det/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jseia/anaconda3/envs/calc_det/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/home/jseia/anaconda3/envs/calc_det/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/home/jseia/anaconda3/envs/calc_det/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/home/jseia/anaconda3/envs/calc_det/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/home/jseia/anaconda3/envs/calc_det/lib/python3.9/inspect.py\", line 1499, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/home/jseia/anaconda3/envs/calc_det/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/home/jseia/anaconda3/envs/calc_det/lib/python3.9/inspect.py\", line 746, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'labels'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_22094/3537809768.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mall_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mall_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     random_state=0, stratify=all_features['labels'].values)\n",
            "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'labels'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyError' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import sys; sys.path.insert(0, '..')\n",
        "\n",
        "from database.dataset import INBreast_Dataset\n",
        "from mc_candidate_proposal.hough_mc import HoughCalcificationDetection\n",
        "from models.bria2014.haar_extractor import HaarFeatureExtractor\n",
        "from metrics.metrics import get_tp_fp_fn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import general_utils.utils as utils\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "\n",
        "db = INBreast_Dataset(\n",
        "    return_lesions_mask=True,\n",
        "    level='image',\n",
        "    max_lesion_diam_mm=1.,\n",
        "    extract_patches=False,\n",
        "    extract_patches_method='all',  # 'centered'\n",
        "    patch_size=256,\n",
        "    stride=256,\n",
        "    min_breast_fraction_roi=0.5,\n",
        "    normalize=None,\n",
        "    n_jobs=-1,\n",
        "    partitions=['train', 'val']\n",
        ")\n",
        "\n",
        "# BASE_PATH = Path('/home/jseia/Desktop/ml-dl/data_rois/haar_features')\n",
        "# all_features = []\n",
        "# for idx in tqdm(range(30), total=30):\n",
        "#     image_id = db.df.iloc[idx].img_id\n",
        "#     features = pd.read_feather(BASE_PATH/f'{image_id}.fth')\n",
        "#     all_features.append(features)\n",
        "# all_features = pd.concat(all_features, ignore_index=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    all_features.loc[:, all_features.columns!='labels'].values,\n",
        "    all_features['labels'].values, train_size=0.7,\n",
        "    random_state=0, stratify=all_features['labels'].values)\n",
        "\n",
        "# Extract all possible features\n",
        "feature_coord, feature_type = \\\n",
        "    haar_like_feature_coord(width=14, height=14,\n",
        "                            feature_type=['type-2-x', 'type-2-y', 'type-3-x', 'type-3-y', 'type-4'])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train a random forest classifier and assess its performance\n",
        "clf = RandomForestClassifier(n_estimators=1000, max_depth=None, n_jobs=-1, random_state=0)\n",
        "t_start = time()\n",
        "clf.fit(X_train, y_train)\n",
        "time_full_train = time() - t_start\n",
        "auc_full_features = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
        "\n",
        "# Sort features in order of importance and plot the six most significant\n",
        "idx_sorted = np.argsort(clf.feature_importances_)[::-1]\n",
        "\n",
        "fig, axes = plt.subplots(3, 2)\n",
        "for idx, ax in enumerate(axes.ravel()):\n",
        "    image = utils.min_max_norm(images[15], 255).astype('uint8')\n",
        "    image = draw_haar_like_feature(image, 0, 0,\n",
        "                                   images.shape[2],\n",
        "                                   images.shape[1],\n",
        "                                   [feature_coord[idx_sorted[idx]]])\n",
        "    ax.imshow(image)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "_ = fig.suptitle('The most important features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9998361193051458"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "auc_full_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "468 features, or 2.5%, account for 70% of branch points in the random forest.\n"
          ]
        }
      ],
      "source": [
        "cdf_feature_importances = np.cumsum(clf.feature_importances_[idx_sorted])\n",
        "cdf_feature_importances /= cdf_feature_importances[-1]  # divide by max value\n",
        "sig_feature_count = np.count_nonzero(cdf_feature_importances < 0.7)\n",
        "sig_feature_percent = round(sig_feature_count /\n",
        "                            len(cdf_feature_importances) * 100, 1)\n",
        "print((f'{sig_feature_count} features, or {sig_feature_percent}%, '\n",
        "       f'account for 70% of branch points in the random forest.'))\n",
        "\n",
        "# Select the determined number of most informative features\n",
        "feature_coord_sel = feature_coord[idx_sorted[:sig_feature_count]]\n",
        "feature_type_sel = feature_type[idx_sorted[:sig_feature_count]]\n",
        "# Note: it is also possible to select the features directly from the matrix X,\n",
        "# but we would like to emphasize the usage of `feature_coord` and `feature_type`\n",
        "# to recompute a subset of desired features.\n",
        "\n",
        "# Build the computational graph using Dask\n",
        "X = delayed(extract_feature_image(img, feature_type_sel, feature_coord_sel)\n",
        "            for img in images)\n",
        "# Compute the result\n",
        "t_start = time()\n",
        "X = np.array(X.compute(scheduler='single-threaded'))\n",
        "time_subs_feature_comp = time() - t_start\n",
        "\n",
        "y = np.array([1] * len(tp) + [0] * len(fp))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7,\n",
        "                                                    random_state=0,\n",
        "                                                    stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the full feature set took 48.719s, plus 4.570s training, for an AUC of 1.00. Computing the restricted feature set took 0.638s, plus 2.149s training, for an AUC of 1.00.\n"
          ]
        }
      ],
      "source": [
        "t_start = time()\n",
        "clf.fit(X_train, y_train)\n",
        "time_subs_train = time() - t_start\n",
        "\n",
        "auc_subs_features = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
        "\n",
        "summary = ((f'Computing the full feature set took '\n",
        "            f'{time_full_feature_comp:.3f}s, '\n",
        "            f'plus {time_full_train:.3f}s training, '\n",
        "            f'for an AUC of {auc_full_features:.2f}. '\n",
        "            f'Computing the restricted feature set took '\n",
        "            f'{time_subs_feature_comp:.3f}s, plus {time_subs_train:.3f}s '\n",
        "            f'training, for an AUC of {auc_subs_features:.2f}.'))\n",
        "\n",
        "print(summary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "51.330018281936646"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "time_full_feature_comp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A random forest classifier can be trained in order to select the most\n",
        "salient features, specifically for face classification. The idea is to\n",
        "determine which features are most often used by the ensemble of trees.\n",
        "By using only the most salient features in subsequent steps, we can\n",
        "drastically speed up the computation while retaining accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Train a random forest classifier and assess its performance\n",
        "clf = RandomForestClassifier(n_estimators=1000, max_depth=None,\n",
        "                             max_features=100, n_jobs=-1, random_state=0)\n",
        "t_start = time()\n",
        "clf.fit(X_train, y_train)\n",
        "time_full_train = time() - t_start\n",
        "auc_full_features = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
        "\n",
        "# Sort features in order of importance and plot the six most significant\n",
        "idx_sorted = np.argsort(clf.feature_importances_)[::-1]\n",
        "\n",
        "fig, axes = plt.subplots(3, 2)\n",
        "for idx, ax in enumerate(axes.ravel()):\n",
        "    image = images[0]\n",
        "    image = draw_haar_like_feature(image, 0, 0,\n",
        "                                   images.shape[2],\n",
        "                                   images.shape[1],\n",
        "                                   [feature_coord[idx_sorted[idx]]])\n",
        "    ax.imshow(image)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "_ = fig.suptitle('The most important features')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can select the most important features by checking the cumulative sum\n",
        "of the feature importance. In this example, we keep the features\n",
        "representing 70% of the cumulative value (which corresponds to using only 3%\n",
        "of the total number of features).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cdf_feature_importances = np.cumsum(clf.feature_importances_[idx_sorted])\n",
        "cdf_feature_importances /= cdf_feature_importances[-1]  # divide by max value\n",
        "sig_feature_count = np.count_nonzero(cdf_feature_importances < 0.7)\n",
        "sig_feature_percent = round(sig_feature_count /\n",
        "                            len(cdf_feature_importances) * 100, 1)\n",
        "print((f'{sig_feature_count} features, or {sig_feature_percent}%, '\n",
        "       f'account for 70% of branch points in the random forest.'))\n",
        "\n",
        "# Select the determined number of most informative features\n",
        "feature_coord_sel = feature_coord[idx_sorted[:sig_feature_count]]\n",
        "feature_type_sel = feature_type[idx_sorted[:sig_feature_count]]\n",
        "# Note: it is also possible to select the features directly from the matrix X,\n",
        "# but we would like to emphasize the usage of `feature_coord` and `feature_type`\n",
        "# to recompute a subset of desired features.\n",
        "\n",
        "# Build the computational graph using Dask\n",
        "X = delayed(extract_feature_image(img, feature_type_sel, feature_coord_sel)\n",
        "            for img in images)\n",
        "# Compute the result\n",
        "t_start = time()\n",
        "X = np.array(X.compute(scheduler='single-threaded'))\n",
        "time_subs_feature_comp = time() - t_start\n",
        "\n",
        "y = np.array([1] * 100 + [0] * 100)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=150,\n",
        "                                                    random_state=0,\n",
        "                                                    stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the features are extracted, we can train and test a new classifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t_start = time()\n",
        "clf.fit(X_train, y_train)\n",
        "time_subs_train = time() - t_start\n",
        "\n",
        "auc_subs_features = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
        "\n",
        "summary = ((f'Computing the full feature set took '\n",
        "            f'{time_full_feature_comp:.3f}s, '\n",
        "            f'plus {time_full_train:.3f}s training, '\n",
        "            f'for an AUC of {auc_full_features:.2f}. '\n",
        "            f'Computing the restricted feature set took '\n",
        "            f'{time_subs_feature_comp:.3f}s, plus {time_subs_train:.3f}s '\n",
        "            f'training, for an AUC of {auc_subs_features:.2f}.'))\n",
        "\n",
        "print(summary)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "f094a5cfaa0fb3b1e730adb1bd2a385aed1bdbc34460cd7c5bc1913497751e38"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('calc_det')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
