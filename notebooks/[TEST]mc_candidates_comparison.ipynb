{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from database.dataset import INBreast_Dataset\n",
    "from metrics.metrics_utils import get_tp_fp_fn_center_patch_criteria\n",
    "from mc_candidate_proposal.morphology_mc import MorphologyCalcificationDetection\n",
    "from mc_candidate_proposal.hdog_mc import HDoGCalcificationDetection\n",
    "from mc_candidate_proposal.hough_mc import HoughCalcificationDetection\n",
    "\n",
    "from tqdm import tqdm\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define experiment runers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_gsm(threshold, min_distance, area, db, results_path):\n",
    "    normal_ids = db.get_free_of_selected_lesions_imgs_ids()\n",
    "\n",
    "    m_results_path = results_path / 'morphology'\n",
    "    m_results_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    rbd_path = m_results_path / 'recounstructed_by_dialation_img'\n",
    "    shutil.rmtree(rbd_path)\n",
    "    rbd_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    result_det = {}\n",
    "    res = []\n",
    "    for idx in tqdm(range(len(db)), total=len(db)):\n",
    "        case = db[idx]\n",
    "        image = case['img']\n",
    "        image_id = case['img_id']\n",
    "        lesion_mask = case['lesion_mask']\n",
    "        muscle_mask = case['muscle_mask']\n",
    "        muscle_mask = case['muscle_mask']\n",
    "\n",
    "        md = MorphologyCalcificationDetection(\n",
    "            rbd_path, threshold=threshold, min_distance=min_distance,\n",
    "            area=area*area, store_intermediate=False, filter_muscle_region=True)\n",
    "\n",
    "        start = time.time()\n",
    "        candidate_blobs = md.detect(image, image_id, muscle_mask)\n",
    "        t = time.time() - start\n",
    "\n",
    "        tp, fp, fn, ignored_candidates = get_tp_fp_fn_center_patch_criteria(\n",
    "            candidate_blobs, lesion_mask, None, 14)\n",
    "\n",
    "        img_res = {\n",
    "            'img_id': image_id, 'TP': len(tp), 'FP': len(fp), 'FN': len(fn),\n",
    "            'time': t, 'normal': image_id in normal_ids}\n",
    "\n",
    "        res.append(img_res)\n",
    "        result_det[image_id] = {\n",
    "            'tp': tp.loc[:, ['x', 'y', 'radius']].values,\n",
    "            'fp': fp.loc[:, ['x', 'y', 'radius']].values,\n",
    "            'fn': fn.loc[:, ['x', 'y', 'radius']].values}\n",
    "    results_morphology = pd.DataFrame(res)\n",
    "    filename = f'md_th-{threshold}_mindist-{min_distance}_area-{area}'\n",
    "    results_morphology.to_csv(results_path/f'{filename}.csv')\n",
    "    with open(results_path/f'{filename}.pkl', 'wb') as f:\n",
    "        pickle.dump(result_det, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_hdog(dog_parameters, hessian_parameters, db, results_path):\n",
    "    \n",
    "    normal_ids = db.get_free_of_selected_lesions_imgs_ids()\n",
    "    \n",
    "    hdog_results_path = results_path / 'HDoG'\n",
    "    hdog_results_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    processed_imgs_path = hdog_results_path / 'hdog_images'\n",
    "    shutil.rmtree(processed_imgs_path)\n",
    "    processed_imgs_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    detections_path = hdog_results_path / 'hdog_detections'\n",
    "    shutil.rmtree(detections_path)\n",
    "    detections_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    result_det = {}\n",
    "    res = []\n",
    "\n",
    "    for idx in tqdm(range(len(db)), total=len(db)):\n",
    "        case = db[idx]\n",
    "        image = case['img']\n",
    "        image_id = case['img_id']\n",
    "        lesion_mask = case['lesion_mask']\n",
    "        muscle_mask = case['muscle_mask']\n",
    "\n",
    "        hdogd = HDoGCalcificationDetection(\n",
    "            dog_parameters, hessian_parameters, processed_imgs_path, detections_path, filter_muscle_region=True)\n",
    "        \n",
    "        start = time.time()\n",
    "        detections = hdogd.detect(image, image_id, False, False, muscle_mask)\n",
    "        t = time.time() - start\n",
    "\n",
    "        tp, fp, fn, _ = get_tp_fp_fn_center_patch_criteria(\n",
    "            detections, lesion_mask, None, 14)\n",
    "\n",
    "        img_res = {\n",
    "            'img_id': image_id, 'TP': len(tp), 'FP': len(fp), 'FN': len(fn),\n",
    "            'time': t, 'normal': image_id in normal_ids}\n",
    "\n",
    "        res.append(img_res)\n",
    "        result_det[image_id] = {\n",
    "            'tp': tp.loc[:, ['x', 'y', 'radius']].values,\n",
    "            'fp': fp.loc[:, ['x', 'y', 'radius']].values,\n",
    "            'fn': fn.loc[:, ['x', 'y', 'radius']].values}\n",
    "\n",
    "    results_hdog = pd.DataFrame(res)\n",
    "\n",
    "    ms = dog_parameters['min_sigma']\n",
    "    Ms = dog_parameters['max_sigma']\n",
    "    ns = dog_parameters['n_scales']\n",
    "    ns = dog_parameters['n_scales']\n",
    "    dth = dog_parameters['dog_blob_th']\n",
    "    dovp = dog_parameters['dog_overlap']\n",
    "    dmd = dog_parameters['dog_min_dist']\n",
    "    filename = f'hdog_ms-{ms}_Ms-{Ms}_ns-{ns}_dth-{dth}_dovp-{dovp}_dmd-{dmd}'\n",
    "    results_hdog.to_csv(results_path/f'{filename}.csv')\n",
    "    with open(results_path/f'{filename}.pkl', 'wb') as f:\n",
    "        pickle.dump(result_det, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [51:20<00:00, 26.11s/it] \n"
     ]
    }
   ],
   "source": [
    "def run_experiment_hough(dehazing_params, hough1_params, hough2_params, db, results_path):\n",
    "    normal_ids = db.get_free_of_selected_lesions_imgs_ids()\n",
    "\n",
    "    hough_results_path = results_path / 'Hough'\n",
    "    hough_results_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    processed_imgs_path = hough_results_path / 'hough_images'\n",
    "    shutil.rmtree(processed_imgs_path)\n",
    "    processed_imgs_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    back_ext_radius = 50\n",
    "    erosion_iter = 20\n",
    "    erosion_size = 5\n",
    "\n",
    "    result_det_h1 = {}\n",
    "    result_det_h2 = {}\n",
    "    res_h1 = []\n",
    "    res_h2 = []\n",
    "\n",
    "    for idx in tqdm(range(len(db)), total=len(db)):\n",
    "        case = db[idx]\n",
    "        image = case['img']\n",
    "        image_id = case['img_id']\n",
    "        lesion_mask = case['lesion_mask']\n",
    "        muscle_mask = case['muscle_mask']\n",
    "\n",
    "        hd = HoughCalcificationDetection(\n",
    "            dehazing_params, back_ext_radius, processed_imgs_path, hough1_params, hough2_params,\n",
    "            erosion_iter=erosion_iter, erosion_size=erosion_size, filter_muscle_region=True)\n",
    "\n",
    "        start = time.time()\n",
    "        h1_circles, h2_circles = hd.detect(image, image_id,\n",
    "            load_processed_images=False, hough2=True, muscle_mask=muscle_mask)\n",
    "        t = time.time() - start\n",
    "\n",
    "        tp, fp, fn, ignored_candidates = get_tp_fp_fn_center_patch_criteria(h1_circles, lesion_mask, None, 14)\n",
    "        result_det_h1[image_id] = {\n",
    "            'tp': tp.loc[:, ['x', 'y', 'radius']].values,\n",
    "            'fp': fp.loc[:, ['x', 'y', 'radius']].values,\n",
    "            'fn': fn.loc[:, ['x', 'y', 'radius']].values}\n",
    "        img_res_h1 = {'img_id': image_id, 'TP': len(tp), 'FP': len(fp), 'FN': len(fn),\n",
    "            'time': t, 'normal': image_id in normal_ids}\n",
    "        res_h1.append(img_res_h1)\n",
    "\n",
    "        tp, fp, fn, ignored_candidates = get_tp_fp_fn_center_patch_criteria(h2_circles, lesion_mask, None, 14)\n",
    "        result_det_h2[image_id] = {\n",
    "            'tp': tp.loc[:, ['x', 'y', 'radius']].values,\n",
    "            'fp': fp.loc[:, ['x', 'y', 'radius']].values,\n",
    "            'fn': fn.loc[:, ['x', 'y', 'radius']].values}\n",
    "        img_res_h2 = {'img_id': image_id, 'TP': len(tp), 'FP': len(fp), 'FN': len(fn),\n",
    "            'time': t, 'normal': image_id in normal_ids}\n",
    "        res_h2.append(img_res_h2)\n",
    "\n",
    "    results_hough_h1 = pd.DataFrame(res_h1)\n",
    "    results_hough_h2 = pd.DataFrame(res_h2)\n",
    "\n",
    "    filename = f'hough_default'\n",
    "    results_hough_h1.to_csv(results_path/f'{filename}_h1.csv')\n",
    "    with open(results_path/f'{filename}_h1.pkl', 'wb') as f:\n",
    "        pickle.dump(result_det_h1, f)\n",
    "\n",
    "    results_hough_h2.to_csv(results_path/f'{filename}_h2.csv')\n",
    "    with open(results_path/f'{filename}_h2.pkl', 'wb') as f:\n",
    "        pickle.dump(result_det_h2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results_path):\n",
    "    filename = 'md_th-0.95_mindist-6_area-14'\n",
    "    results_morphology95 = pd.read_csv(results_path/f'{filename}.csv')\n",
    "    results_morphology95['method'] = 'gs_morph_095'\n",
    "\n",
    "    filename = 'md_th-0.97_mindist-6_area-14'\n",
    "    results_morphology = pd.read_csv(results_path/f'{filename}.csv')\n",
    "    results_morphology['method'] = 'gs_morph_097'\n",
    "\n",
    "    filename = 'hdog_ms-1_Ms-3_ns-20_dth-0.006_dmd-6'\n",
    "    results_hdog = pd.read_csv(results_path/f'{filename}.csv')\n",
    "    results_hdog['method'] = 'hdog'\n",
    "\n",
    "    results_hough_h1 = pd.read_csv(results_path/'hough_default_h1.csv')\n",
    "    results_hough_h1['method'] = 'hough_h1'\n",
    "    results_hough_h2 = pd.read_csv(results_path/'hough_default_h2.csv')\n",
    "    results_hough_h2['method'] = 'hough_h2'\n",
    "\n",
    "    results = pd.concat([results_morphology95, results_morphology, results_hdog, results_hough_h1, results_hough_h2], ignore_index=True)\n",
    "    results['FPR'] = results['FP'] / (results['FP'] + results['TP'])\n",
    "    results['mfpi'] = (results['FP'] / len(results)).sum()\n",
    "    results['sens'] = results['TP'] / (results['TP'] + results['FN'])\n",
    "    results.loc[~results.normal, 'fp_per_tp'] = results['FP'] / (results['TP'])\n",
    "    results.loc[results.normal, 'fp_per_tp'] = results['FP']\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('Sensitivity vs method')\n",
    "    sns.boxplot(data=results, x='method', y='sens')\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('False positives per tp per image vs method')\n",
    "    sns.boxplot(data=results, x='method', y='fp_per_tp')\n",
    "    plt.ylim(0, 2000)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('False positives per tp per image vs method')\n",
    "    sns.boxplot(data=results, x='method', y='fp_per_tp')\n",
    "    plt.yscale('log')\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('False positives per image on normal images vs method')\n",
    "    sns.boxplot(data=results.loc[results.normal], x='method', y='fp_per_tp')\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('Computation time per image vs method')\n",
    "    sns.boxplot(data=results, x='method', y='time')\n",
    "    # plt.yscale('log')\n",
    "    sns.despine()\n",
    "    plt.ylabel('time [s]')\n",
    "    plt.ylim([0, 70])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments with pectoral supression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = INBreast_Dataset(\n",
    "    return_lesions_mask=True,\n",
    "    level='image',\n",
    "    max_lesion_diam_mm=None,\n",
    "    extract_patches=False,\n",
    "    partitions = ['validation'],\n",
    "    lesion_types = ['calcification', 'cluster'],\n",
    "    cropped_imgs = True,\n",
    "    keep_just_images_of_lesion_type = False,\n",
    "    use_muscle_mask=True,\n",
    "    ignore_diameter_px = 15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path.cwd().parent.parent / 'data/comparisson_between_detectors_wo_pectoral/'\n",
    "results_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "# GSM\n",
    "threshold = 0.97\n",
    "min_distance = 6\n",
    "area = 14\n",
    "run_experiment_gsm(threshold, min_distance, area, results_path)\n",
    "\n",
    "threshold = 0.95\n",
    "min_distance = 6\n",
    "area = 14\n",
    "run_experiment_gsm(threshold, min_distance, area, results_path)\n",
    "\n",
    "\n",
    "# HDOG\n",
    "dog_parameters = {\n",
    "    'min_sigma': 1,\n",
    "    'max_sigma': 3,\n",
    "    'n_scales': 20,\n",
    "    'sigma_ratio': None,\n",
    "    'dog_blob_th': 0.006,\n",
    "    'dog_overlap': 0.2,\n",
    "    'dog_min_dist': 6,\n",
    "}\n",
    "\n",
    "hessian_parameters = {\n",
    "    'method': 'eigenval',\n",
    "    'hessian_threshold': None,\n",
    "    'hessian_th_divider': 300\n",
    "}\n",
    "\n",
    "run_experiment_hdog(dog_parameters, hessian_parameters, results_path)\n",
    "\n",
    "\n",
    "# HOUGH\n",
    "dehazing_params = {'omega': 0.9, 'window_size': 11, 'radius': 40, 'eps': 1e-5}\n",
    "\n",
    "hough1_params = {'method': cv2.HOUGH_GRADIENT, 'dp': 1, 'minDist': 20,\n",
    "                'param1': 300, 'param2': 8,  'minRadius': 2, 'maxRadius': 20}\n",
    "\n",
    "hough2_params = {'method': cv2.HOUGH_GRADIENT, 'dp': 1, 'minDist': 20,\n",
    "                'param1': 300, 'param2': 10,  'minRadius': 2, 'maxRadius': 20}\n",
    "\n",
    "run_experiment_hough(dehazing_params, hough1_params, hough2_params, db, results_path)\n",
    "\n",
    "# RESULTS\n",
    "plot_results(results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments with pectoral supression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = INBreast_Dataset(\n",
    "    return_lesions_mask=True,\n",
    "    level='image',\n",
    "    max_lesion_diam_mm=None,\n",
    "    extract_patches=False,\n",
    "    partitions = ['validation'],\n",
    "    lesion_types = ['calcification', 'cluster'],\n",
    "    cropped_imgs = True,\n",
    "    keep_just_images_of_lesion_type = False,\n",
    "    use_muscle_mask=False,\n",
    "    ignore_diameter_px = 15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path.cwd().parent.parent / 'data/comparisson_between_detectors_w_pectoral/'\n",
    "results_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# GSM\n",
    "threshold = 0.97\n",
    "min_distance = 6\n",
    "area = 14\n",
    "run_experiment_gsm(threshold, min_distance, area, results_path)\n",
    "\n",
    "threshold = 0.95\n",
    "min_distance = 6\n",
    "area = 14\n",
    "run_experiment_gsm(threshold, min_distance, area, results_path)\n",
    "\n",
    "\n",
    "# HDOG\n",
    "dog_parameters = {\n",
    "    'min_sigma': 1,\n",
    "    'max_sigma': 3,\n",
    "    'n_scales': 20,\n",
    "    'sigma_ratio': None,\n",
    "    'dog_blob_th': 0.006,\n",
    "    'dog_overlap': 0.2,\n",
    "    'dog_min_dist': 6,\n",
    "}\n",
    "\n",
    "hessian_parameters = {\n",
    "    'method': 'eigenval',\n",
    "    'hessian_threshold': None,\n",
    "    'hessian_th_divider': 300\n",
    "}\n",
    "\n",
    "run_experiment_hdog(dog_parameters, hessian_parameters, results_path)\n",
    "\n",
    "\n",
    "# HOUGH\n",
    "dehazing_params = {'omega': 0.9, 'window_size': 11, 'radius': 40, 'eps': 1e-5}\n",
    "\n",
    "hough1_params = {'method': cv2.HOUGH_GRADIENT, 'dp': 1, 'minDist': 20,\n",
    "                'param1': 300, 'param2': 8,  'minRadius': 2, 'maxRadius': 20}\n",
    "\n",
    "hough2_params = {'method': cv2.HOUGH_GRADIENT, 'dp': 1, 'minDist': 20,\n",
    "                'param1': 300, 'param2': 10,  'minRadius': 2, 'maxRadius': 20}\n",
    "\n",
    "run_experiment_hough(dehazing_params, hough1_params, hough2_params, db, results_path)\n",
    "\n",
    "# RESULTS\n",
    "plot_results(results_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f094a5cfaa0fb3b1e730adb1bd2a385aed1bdbc34460cd7c5bc1913497751e38"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('calc_det')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
