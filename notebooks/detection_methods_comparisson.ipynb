{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from database.dataset import INBreast_Dataset\n",
    "from general_utils.plots import simple_im_show, plot_blobs2, plot_blobs\n",
    "from tqdm import tqdm\n",
    "\n",
    "from general_utils.utils import get_center_bboxes\n",
    "from metrics.metrics import get_tp_fp_fn\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mc_candidate_proposal.hdog_mc import HDoGCalcificationDetection\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = INBreast_Dataset(\n",
    "    return_lesions_mask=True,\n",
    "    level='image',\n",
    "    max_lesion_diam_mm=1.0, #max 315 pixels area\n",
    "    extract_patches=False,\n",
    "    extract_patches_method='all',  # 'centered'\n",
    "    patch_size=256,\n",
    "    stride=256,\n",
    "    min_breast_fraction_roi=0.5,\n",
    "    normalize=None,\n",
    "    partitions = ['train'],\n",
    "    n_jobs=-1,\n",
    "    lesion_types=['calcification']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import label\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class MorphologyDetection:\n",
    "    def __init__(\n",
    "        self, rbd_img_path: str, threshold: float, alternative: bool = False,\n",
    "        store_intermediate: bool = True, use_precomputed: bool=False\n",
    "    ):\n",
    "        self.use_alternative = alternative\n",
    "        self.rbd_img_path = Path(rbd_img_path)\n",
    "        self.threshold = threshold\n",
    "        self.store_intermediate = store_intermediate\n",
    "        self.use_precomputed = use_precomputed\n",
    "        if self.use_alternative:\n",
    "            self.dilation_k_size = 14\n",
    "        else:\n",
    "            self.dilation_k_size = 20\n",
    "\n",
    "    def detect(self, image: np.ndarray, image_id: int, ):\n",
    "\n",
    "        self.image = image\n",
    "\n",
    "        # load or create reconstructed by dialation image\n",
    "        rbd_image = None\n",
    "        if (self.rbd_img_path/f'{image_id}.tiff').exists() and self.use_precomputed:\n",
    "            rbd_image = cv2.imread(\n",
    "                str(self.rbd_img_path/f'{image_id}.tiff'),  cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "        if rbd_image is None:\n",
    "            rbd_image = self.reconstruction_by_dialation(\n",
    "                image, circle_size=self.dilation_k_size)\n",
    "            if self.store_intermediate:\n",
    "                cv2.imwrite(str(self.rbd_img_path/f'{image_id}.tiff'), rbd_image)\n",
    "\n",
    "        # erode breast boundary to avoid FP there\n",
    "        rbd_image_no_bbound = self.breast_boundary_erosion(rbd_image)\n",
    "\n",
    "        # intensity thresholding\n",
    "        trheshold = np.quantile(\n",
    "            rbd_image_no_bbound[rbd_image_no_bbound != 0].ravel(), q=self.threshold)\n",
    "        thr1_rbd = rbd_image_no_bbound.copy()\n",
    "        thr1_rbd[thr1_rbd <= trheshold] = 0\n",
    "\n",
    "        if self.use_alternative:\n",
    "            quant = 0.8\n",
    "            trheshold = np.quantile(rbd_image_no_bbound[thr1_rbd > 0].ravel(), q=quant)\n",
    "            thr_rbd = rbd_image_no_bbound.copy()\n",
    "            thr_rbd[thr_rbd <= trheshold] = 0\n",
    "        else:\n",
    "            thr_rbd = thr1_rbd\n",
    "\n",
    "        # connected components extraction and filtering\n",
    "        markers = self.connected_components_extraction(thr1_rbd)\n",
    "        cc_mask = self.connected_components_filtering(markers)\n",
    "        return cc_mask\n",
    "\n",
    "    def reconstruction_by_dialation(\n",
    "        self, mask: np.ndarray, rect_size: int = 3, circle_size: int = 20\n",
    "    ):\n",
    "        \"\"\"Reconstructs image using grayscale dialation\n",
    "        Args:\n",
    "            mask (np.ndarray): Image arre of type float or np.uint8\n",
    "            rect_size (int, optional):\n",
    "                Size of the SE used for geodesic reconstruction. Defaults to 3.\n",
    "            circle_size (int, optional):\n",
    "                Size of the SE used for creating a marker image. Defaults to 20.\n",
    "        \"\"\"\n",
    "        rect_SE = cv2.getStructuringElement(\n",
    "            cv2.MORPH_RECT, (rect_size, rect_size))\n",
    "        circle_SE = cv2.getStructuringElement(\n",
    "            cv2.MORPH_ELLIPSE, (circle_size, circle_size))\n",
    "\n",
    "        marker_cur = cv2.morphologyEx(mask, cv2.MORPH_OPEN, circle_SE)\n",
    "        marker_prev = np.zeros_like(marker_cur)\n",
    "        while (not (marker_prev == marker_cur).all()):\n",
    "            marker_prev = marker_cur.copy()\n",
    "            marker_cur = cv2.min(cv2.dilate(marker_prev, rect_SE), mask)\n",
    "        return mask - marker_cur\n",
    "\n",
    "    def breast_boundary_erosion(self, rbd_image: np.ndarray):\n",
    "        \"\"\"Use breast mask and remove its contour from the detection image\"\"\"\n",
    "        erosion_size = 5\n",
    "        erosion_iter = 10\n",
    "\n",
    "        breast_mask = (self.image != 0).astype(np.uint8)\n",
    "        structuring_element = cv2.getStructuringElement(cv2.MORPH_RECT,\n",
    "                                                        (erosion_size, erosion_size))\n",
    "        breast_boundary_mask = cv2.erode(breast_mask, structuring_element,\n",
    "                                         iterations=erosion_iter)\n",
    "        rbd_image_no_bbound = rbd_image.copy()\n",
    "        rbd_image_no_bbound[breast_boundary_mask == 0] = 0\n",
    "        return rbd_image_no_bbound\n",
    "\n",
    "    def connected_components_extraction(self, thr1_rbd: np.ndarray):\n",
    "        \"\"\"Finds connected components\"\"\"\n",
    "        # binarize and perform connected components labeling\n",
    "        thr1_rbd_bin = self.to_uint8(255*(thr1_rbd > 0))\n",
    "        markers, _ = label(thr1_rbd_bin, background=0,\n",
    "                           return_num=True, connectivity=1)\n",
    "        return markers\n",
    "\n",
    "    def connected_components_filtering(self, markers: np.ndarray):\n",
    "        \"\"\"Filter connected components\"\"\"\n",
    "        # connected components filtering\n",
    "        selected_cc = []\n",
    "        candidate_blobs = []\n",
    "        out = np.zeros_like(markers, dtype='uint16')\n",
    "        contours, _ = cv2.findContours(\n",
    "            np.where(markers > 0, 255, 0).astype('uint8'),\n",
    "            cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "        for obj in contours:\n",
    "            A = cv2.contourArea(obj)\n",
    "            if 14*14 > A >= 0:\n",
    "                selected_cc.append(obj)\n",
    "                center, r = cv2.minEnclosingCircle(obj)\n",
    "                candidate_blobs.append((center[0], center[1], r))\n",
    "        out = cv2.drawContours(out, selected_cc, -1, 255, -1)\n",
    "        return out, candidate_blobs\n",
    "\n",
    "    @staticmethod\n",
    "    def min_max_norm(img):\n",
    "        return (img - img.min())/(img.max() - img.min())\n",
    "\n",
    "    def to_uint8(self, img):\n",
    "        return (255*self.min_max_norm(img)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [16:07<00:00,  6.28s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "res_gray_morph_2_th = []\n",
    "for idx in tqdm(range(len(db))):\n",
    "    rbd_path = '/home/jseia/Desktop/ml-dl/data/recounstructed_by_dialation_img'\n",
    "    md = MorphologyDetection(rbd_path, threshold=0.97, alternative=True, store_intermediate=True, use_precomputed=False)\n",
    "    case = db[idx]\n",
    "    image = case['img']\n",
    "    image_id = db.df.iloc[idx].img_id\n",
    "    radiouses = case['radiuses']\n",
    "    true_bboxes = db[idx]['lesion_bboxes']\n",
    "    start = time.time()\n",
    "    selected_cc_mask, candidate_blobs = md.detect(image, image_id)\n",
    "    t = time.time() - start\n",
    "    tp, fp, fn, gt_d, close_fp = get_tp_fp_fn(true_bboxes, radiouses, candidate_blobs, 7, 0.1)\n",
    "    img_res = {'img_id': image_id, 'TP': len(tp), 'FP': len(fp), 'FN': len(fn), 'time': t, 'size': image.size}\n",
    "    res_gray_morph_2_th.append(img_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [15:34<00:00,  6.07s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "res_gray_morph = []\n",
    "for idx in tqdm(range(len(db))):\n",
    "    rbd_path = '/home/jseia/Desktop/ml-dl/data/recounstructed_by_dialation_img'\n",
    "    md = MorphologyDetection(rbd_path, threshold=0.97, alternative=True, store_intermediate=False, use_precomputed=False)\n",
    "    case = db[idx]\n",
    "    image = case['img']\n",
    "    image_id = db.df.iloc[idx].img_id\n",
    "    radiouses = case['radiuses']\n",
    "    true_bboxes = db[idx]['lesion_bboxes']\n",
    "    start = time.time()\n",
    "    selected_cc_mask, candidate_blobs = md.detect(image, image_id)\n",
    "    t = time.time() - start\n",
    "    tp, fp, fn, gt_d, close_fp = get_tp_fp_fn(true_bboxes, radiouses, candidate_blobs, 7, 0.1)\n",
    "    img_res = {'img_id': image_id, 'TP': len(tp), 'FP': len(fp), 'FN': len(fn), 'time': t, 'size': image.size}\n",
    "    res_gray_morph.append(img_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/154 [02:00<5:07:18, 120.51s/it]remove '/home/jseia/Desktop/ml-dl/calc-det/notebooks/../data/hdog_preprocessed_images/dog_ms-1_sr-None_Ms-3_m-eigenval.hdf5': No such file or directory\n",
      "rm: cannot remove '/home/jseia/Desktop/ml-dl/calc-det/notebooks/../data/hdog_detections/det_ms-1_sr-None_Ms-3_m-eigenval_dth-0.006.hdf5': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Default parameters\n",
    "dog_parameters = {\n",
    "    'min_sigma': 1,\n",
    "    'max_sigma': 3,\n",
    "    'sigma_ratio': None,\n",
    "    'n_scales': 20,\n",
    "    'dog_blob_th': 0.006,\n",
    "    'dog_overlap': 0.2\n",
    "}\n",
    "\n",
    "hessian_parameters = {\n",
    "    'method': 'eigenval',\n",
    "    'hessian_threshold': None,\n",
    "    'hessian_th_divider': 300\n",
    "}\n",
    "\n",
    "res_hdog_sens = []\n",
    "for idx in tqdm(range(len(db))):\n",
    "    rbd_path = '/home/jseia/Desktop/ml-dl/data/recounstructed_by_dialation_img'\n",
    "    md = HDoGCalcificationDetection(dog_parameters, hessian_parameters)\n",
    "    case = db[idx]\n",
    "    image = case['img']\n",
    "    image_id = db.df.iloc[idx].img_id\n",
    "    radiouses = case['radiuses']\n",
    "    true_bboxes = db[idx]['lesion_bboxes']\n",
    "    start = time.time()\n",
    "    candidate_blobs, _ = md.detect(image, image_id, False)\n",
    "    t = time.time() - start\n",
    "    tp, fp, fn, gt_d, close_fp = get_tp_fp_fn(true_bboxes, radiouses, candidate_blobs, 7, 0.1)\n",
    "    img_res = {'img_id': image_id, 'TP': len(tp), 'FP': len(fp), 'FN': len(fn), 'time': t, 'size': image.size}\n",
    "    res_hdog_sens.append(img_res)\n",
    "    md.delete_hdog_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters\n",
    "dog_parameters = {\n",
    "    'min_sigma': 1,\n",
    "    'max_sigma': 3,\n",
    "    'sigma_ratio': None,\n",
    "    'n_scales': 20,\n",
    "    'dog_blob_th': 0.006,\n",
    "    'dog_overlap': 0.8\n",
    "}\n",
    "\n",
    "hessian_parameters = {\n",
    "    'method': 'eigenval',\n",
    "    'hessian_threshold': None,\n",
    "    'hessian_th_divider': 50\n",
    "}\n",
    "\n",
    "# max_sigma 3, overlap 0.8, n_scales 20, divider = 50\n",
    "\n",
    "res_hdog_esp = []\n",
    "for idx in tqdm(range(len(db))):\n",
    "    rbd_path = '/home/jseia/Desktop/ml-dl/data/recounstructed_by_dialation_img'\n",
    "    md = HDoGCalcificationDetection(dog_parameters, hessian_parameters)\n",
    "    case = db[idx]\n",
    "    image = case['img']\n",
    "    image_id = db.df.iloc[idx].img_id\n",
    "    radiouses = case['radiuses']\n",
    "    true_bboxes = db[idx]['lesion_bboxes']\n",
    "    start = time.time()\n",
    "    candidate_blobs, _ = md.detect(image, image_id), False\n",
    "    t = time.time() - start\n",
    "    tp, fp, fn, gt_d, close_fp = get_tp_fp_fn(true_bboxes, radiouses, candidate_blobs, 7, 0.1)\n",
    "    img_res = {'img_id': image_id, 'TP': len(tp), 'FP': len(fp), 'FN': len(fn), 'time': t, 'size': image.size}\n",
    "    res_hdog_esp.append(img_res)\n",
    "    md.delete_hdog_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(res_)\n",
    "res['sensitivity'] = res.TP / (res.TP + res.FN)\n",
    "res['fpr'] = res.FP / (res.FP + res.TP)\n",
    "res['mode'] = 'original'\n",
    "\n",
    "results = pd.concat([res, res_alt])\n",
    "results.to_csv('/home/jseia/Desktop/ml-dl/data/recounstructed_by_dialation_img/results')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.boxplot(data=results, x='mode', y='sensitivity')\n",
    "sns.despine()\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=results, x='mode', y='fpr')\n",
    "sns.despine()\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=results, x='mode', y='time')\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f094a5cfaa0fb3b1e730adb1bd2a385aed1bdbc34460cd7c5bc1913497751e38"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('calc_det')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
