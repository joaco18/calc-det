{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "thispath = Path.cwd().resolve()\n",
    "import sys; sys.path.insert(0, str(thispath.parent))\n",
    "\n",
    "from database.dataset import INBreast_Dataset\n",
    "import general_utils.utils as utils\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List, Tuple\n",
    "import torchvision.transforms as T\n",
    "\n",
    "datapath = thispath.parent / \"data\" / \"INbreast Release 1.0\"\n",
    "\n",
    "\n",
    "class INBreast_Dataset_pytorch(INBreast_Dataset):\n",
    "    def __init__(\n",
    "        self, imgpath: Path = datapath/'AllPNGs',\n",
    "        mask_path: Path = datapath/'AllMasks',\n",
    "        dfpath: Path = datapath,\n",
    "        lesion_types: List[str] = ['calcification', 'cluster'],\n",
    "        transform: List[str] = None,\n",
    "        data_aug: List[str] = None,\n",
    "        partitions: List[str] = ['train', 'validation', 'test'],\n",
    "        extract_patches: bool = True,\n",
    "        delete_previous: bool = True,\n",
    "        extract_patches_method: str = 'all',\n",
    "        patch_size: int = 224,\n",
    "        stride: Tuple[int] = 100,\n",
    "        min_breast_fraction_roi: float = 0.7,\n",
    "        n_jobs: int = -1,\n",
    "        cropped_imgs: bool = True,\n",
    "        ignore_diameter_px: int = 15,\n",
    "        neg_to_pos_ratio: int = None,\n",
    "        balancing_seed: int = 0\n",
    "    ):\n",
    "        super(INBreast_Dataset_pytorch, self).__init__(\n",
    "            imgpath=imgpath, mask_path=mask_path, dfpath=dfpath, lesion_types=lesion_types,\n",
    "            transform=transform, data_aug=data_aug, partitions=partitions, delete_previous=delete_previous,\n",
    "            extract_patches=extract_patches, extract_patches_method=extract_patches_method,\n",
    "            patch_size=patch_size, stride=stride, min_breast_fraction_roi=min_breast_fraction_roi,\n",
    "            n_jobs=n_jobs, cropped_imgs=cropped_imgs, ignore_diameter_px=ignore_diameter_px,\n",
    "            level = 'rois', return_lesions_mask = False, max_lesion_diam_mm = None, use_muscle_mask = False\n",
    "        )\n",
    "        self.neg_to_pos_ratio = neg_to_pos_ratio\n",
    "        self.balancing_seed = balancing_seed\n",
    "        if neg_to_pos_ratio is not None:\n",
    "            self.balance_dataset()\n",
    "\n",
    "    def balance_dataset(self):\n",
    "        n_pos = self.df.loc[self.df.label=='abnormal', :].shape[0]\n",
    "        n_neg = len(self.df) - n_pos\n",
    "        n_to_sample = n_pos * self.neg_to_pos_ratio\n",
    "        if n_to_sample > n_neg:\n",
    "            n_to_sample = n_neg\n",
    "        self.df = pd.concat([\n",
    "            self.df.loc[self.df.label=='abnormal', :],\n",
    "            self.df.loc[self.df.label=='abnormal', :].sample(n=n_to_sample, replace=False, random_state=self.balancing_seed)\n",
    "        ], ignore_index=True)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        sample[\"label\"] = self.labels[idx]\n",
    "\n",
    "        img_path = self.patch_img_path / self.df['filename'].iloc[idx]\n",
    "        img = cv2.imread(str(img_path), cv2.IMREAD_ANYDEPTH)\n",
    "        # Convert all images in left oriented ones\n",
    "        side = self.df['side'].iloc[idx]\n",
    "        if side == 'R' and self.level == 'image':\n",
    "            img = cv2.flip(img, 1)\n",
    "\n",
    "        img = utils.min_max_norm(img, 1).astype('float32')\n",
    "        # Apply data augmentations\n",
    "        # if self.data_aug is not None:\n",
    "        #     transform_seed = np.random.randint(self.seed)\n",
    "        #     torch.manual_seed(transform_seed)\n",
    "        #     img = self.data_aug(img)\n",
    "\n",
    "        sample['img'] = np.expand_dims(img, 0)\n",
    "\n",
    "        patch_bbox = self.df['patch_bbox'].iloc[idx]\n",
    "        if isinstance(patch_bbox, str):\n",
    "            patch_bbox = utils.load_patch_coords(patch_bbox)\n",
    "        sample[\"patch_bbox\"] = patch_bbox\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "torch.Size([1, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "val_dataset = INBreast_Dataset_pytorch(\n",
    "        lesion_types = ['calcification', 'cluster'],\n",
    "        transform = transforms,\n",
    "        data_aug = None,\n",
    "        partitions = ['validation'],\n",
    "        extract_patches = False,\n",
    "        delete_previous = False,\n",
    "        extract_patches_method = 'all',\n",
    "        patch_size = 224,\n",
    "        stride = 100,\n",
    "        min_breast_fraction_roi = 0.7,\n",
    "        n_jobs = -1,\n",
    "        cropped_imgs = True,\n",
    "        ignore_diameter_px = 15,\n",
    "        neg_to_pos_ratio = None\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True, sampler=None,\n",
    "           batch_sampler=None, num_workers=4, pin_memory=False, drop_last=False)\n",
    "\n",
    "for i in val_dataloader:\n",
    "    print(type(i['img']))\n",
    "    print(i['img'].dtype)\n",
    "    print(i['img'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc10e5baa10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.uint8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torch.nn.Sequential(\n",
    "    T.RandomHorizontalFlip(p=0.3),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (261045667.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_182174/261045667.py\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    transforms = transforms.RandomApply(([]), p=0.3)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.transforms import InterpolationMode\n",
    "def show(imgs):\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img[0].to('cpu')\n",
    "        print(img.dtype)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "transforms = torch.nn.ModuleList(\n",
    "    T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0, hue=0),\n",
    "    T.RandomAffine(\n",
    "        degrees=(0, 180), translate=None, scale=(0,10), shear=((2, 2), ()),\n",
    "        interpolation=InterpolationMode.BILINEAR, fill=0, resample=None\n",
    ")\n",
    "\n",
    "transforms = transforms.RandomApply(([]), p=0.3)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "img1 = i['img'].to(device)\n",
    "\n",
    "transformed_img1 = transforms(img1)\n",
    "show([transformed_img1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sphinx_gallery_thumbnail_path = \"../../gallery/assets/transforms_thumbnail.png\"\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "orig_img = i['img']\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def plot(imgs, with_orig=True, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        row = [orig_img] + row if with_orig else row\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Original image')\n",
    "        axs[0, 0].title.set_size(8)\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (1, 1, 224, 224) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_182174/3485507690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mjitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColorJitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrightness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mjitted_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjitted_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_182174/1158487261.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(imgs, with_orig, row_title, **imshow_kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcol_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mimshow_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5607\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5609\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5610\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5611\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/calc_det/lib/python3.9/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    707\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    708\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 709\u001b[0;31m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[1;32m    710\u001b[0m                             .format(self._A.shape))\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (1, 1, 224, 224) for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVYUlEQVR4nO3df4xV553f8fd3YUfbOE7ibtgmcHHWs0PHgEuizOC4UbXKahWB6QYklEZjtWvVToVo7ab5by1V3SpRpJI/KrUJrkckcixLCWilbhZaA65kybWbjYMvaUwNls0AXc+MXRnbiE2bCDzst3/MNcyPazhzmbkXnvN+SVeec8/DmWc+fu5nzpy5c29kJpKksvxGrycgSVp8lrskFchyl6QCWe6SVCDLXZIKZLlLUoEs9w5FxOMR8VZEvPwB+yMivhMRYxFxLCI+2+05dpuZzGcm85lJd1junXsC2HyV/fcCa1q3HcBjXZhTrz2Bmcz1BGYy1xOYyZKz3DuUmc8B715lyDbgyZz2AvCxiPhkd2bXG2Yyn5nMZybdsbzXEyjYKmB8xvZE6743Zw6KiB1Mn51wyy23DN15551dm+BSuOuuuxgbG2N4eHjenz5/9KMf5ROf+MSOiPhOZq7gAzKBsnIxk/mqZDI8PPyjo0ePvg0cowaZVHX06NG3W2vl6jLTW4c34HeBlz9g31PAP5ix/QwwdLXjDQ0N5c3uzJkzuX79+rb7tmzZks8//3wCzayYSRaQi5nMVyWTzEygWZdMqnp/rVzr5mWZpTMBrJ6x3QDe6NFcbgiNRoPx8fFZd2EmZjKHmSwOy33pHADub/3m/x7gfGbO+7GyTrZu3cqTTz4JgJlMM5P53s9k+iSVWzCTjnjNvUMRsRf4AvDxiJgA/i3wmwCZOQocBLYAY8CvgAd6M9Puue+++3j22Wd5++23aTQafOMb3+C9994DYOfOnWzZsoWDBw8C3AV8DzMxk6tkMjAwAPAp4Pd7Od+bVbS+O+oGMDw8nM1ms9fTWHIRcTQzh6uOr0MuZtLeQnIxk9m8LCNJBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcu9QRGyOiFcjYiwiHmmz/6MR8V8i4qWIOB4RD/Rint10+PBhBgcHGRgYYNeuXfP2nz9/ni996UsA6+qSCVTLBRhwrVxR17WymCz3DkTEMuBR4F5gHXBfRKybM+wh4ERmfhr4AvDvI6KvqxPtokuXLvHQQw9x6NAhTpw4wd69ezlx4sSsMY8++ijr1q0DOEENMoHquQC/dq1cUce1stgs987cDYxl5unMvAjsA7bNGZPArRERwIeBd4Gp7k6ze44cOcLAwAD9/f309fUxMjLC/v37Z42JCH75y1++v1l8JlA9F2CZa+WKOq6VxWa5d2YVMD5je6J130y7gbXAG8D/Av5VZv7N3ANFxI6IaEZE8+zZs0s13yU3OTnJ6tWrL283Gg0mJydnjXn44Yd55ZVXADZwlUygfrkAv4Vr5bKqa6WUTJaC5d6ZaHNfztneBPwCWAl8BtgdER+Z948y92TmcGYOr1ixYrHn2TWZc7/8y2eklz399NN85jOfATjGVTJpHa9WuQC/xrVyWdW1UkomS8Fy78wEsHrGdoPps66ZHgD+PKeNAWeAO7s0v65rNBqMj1/5YWZiYoKVK1fOGvODH/yA7du3A1CHTKB6LsA518oVdVwri81y78yLwJqIuKP1S54R4MCcMa8DfwgQEX8HGAROd3WWXbRx40ZOnjzJmTNnuHjxIvv27WPr1q2zxtx+++0888wzQD0ygeq5AB+BeuTiWumSzPTWwQ3YArwGnAL+deu+ncDO1scrgf/G9PXCl4F/cq1jDg0N5c3sqaeeyjVr1mR/f39+61vfyszMxx57LB977LHMzJycnMwvfvGLCfyqaiZZk1yA866V61srN3smVQHNrPC4iWxz/Uu9MTw8nM1ms9fTWHIRcTQzh6uOr0MuZtLeQnIxk9m8LCNJBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFeia5R4Rj0fEWxHx8gfsj4j4TkSMRcSxiPjs4k9TkrQQVc7cnwA2X2X/vcCa1m0H8Nj1T0uSdD2uWe6Z+Rzw7lWGbAOezGkvAB+LiE8u1gQlSQu3fBGOsQoYn7E90brvzbkDI2IH02f33HLLLUN33nnnInz6G9vRo0ffzswVvZ6HpHpZjHKPNvdlu4GZuQfYAzA8PJzNZnMRPv2NLSL+qtdzkFQ/i/FsmQlg9YztBvDGIhxXktShxSj3A8D9rWfN3AOcz8x5l2QkSd1T5amQe4GfAoMRMRERX42InRGxszXkIHAaGAO+B/yLJZvtDeTw4cMMDg4yMDDArl272o559tlnAdZFxPGI+O/dnF8vmEl7VXIBbo2IX9QlF9dKF2RmT25DQ0N5s5qamsr+/v48depUXrhwITds2JDHjx+fNebcuXO5du3aBI5lJsDvpJksOJOsSS7Ar4Hb07WSmfV7/CwE0MwKjxv/QrUDR44cYWBggP7+fvr6+hgZGWH//v2zxvzoRz9i+/btABcBMvOtHky1a8ykvaq5AOcy83UoPxfXSndY7h2YnJxk9eorv0NuNBpMTk7OGvPaa69x7tw5mL6cdTQi7m93rIjYERHNiGiePXt2Kae9pBYzE6hfLsDyiHjWtTKtbo+fpWC5d2D6J6PZImY/I3RqaoqjR48CnAQ2Af8mIv5um2PtyczhzBxeseLmfTr8YmbSOl6tcgE+BPxDXCtA/R4/S8Fy70Cj0WB8/MrfbU1MTLBy5cp5YzZv3gzwN5n5NvAc8OluzrObzKS9qrkAf52Z/68OubhWusNy78DGjRs5efIkZ86c4eLFi+zbt4+tW7fOGrNt2zaef/55ACLiQ8DngFe6P9vuMJP2quYCfDgiltchF9dKd1juHVi+fDm7d+9m06ZNrF27lq985SusX7+e0dFRRkdHAVi7du37Zx7rgSPA9zOz7StrlsBM2quaC3AeOEYNcnGtdEe0u/7VDTV6+YGjmTlcZayZtFeHXMykPR8/81XNxDN3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlUq94jYHBGvRsRYRDzSZv8XIuJ8693bfxERf7r4U5UkVbX8WgMiYhnwKPBFYAJ4MSIOZOaJOUOfz8w/WoI5SpIWqMqZ+93AWGaezsyLwD5g29JOS5J0PaqU+ypgfMb2ROu+uf5+RLwUEYciYn27A/lO5ZLUHVXKPdrcN/ftm34OfCozPw18F/iLdgfyncolqTuqlPsEsHrGdgN4Y+aAzPzrzPy/rY8PAr8ZER9ftFlKkhakSrm/CKyJiDsiog8YAQ7MHBARn4iIaH18d+u47yz2ZCVJ1Vzz2TKZORURDwNPA8uAxzPzeETsbO0fBb4M/POImAJ+DYxkr955W5J07XKHy5daDs65b3TGx7uB3Ys7NUlSp/wLVUkqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7h06fPgwg4ODDAwMsGvXrqsN/VBEXIqIL3drbr1iJu1VzSUiNtYlF9fK0rPcO3Dp0iUeeughDh06xIkTJ9i7dy8nTpxoO47pd656uttz7DYzaa9qLi3fpga5uFa6w3LvwJEjRxgYGKC/v5++vj5GRkbYv3//vHHf/e53Ac4Bb3V7jt1mJu1VzQX4HeA/U4NcXCvdYbl3YHJyktWrr7ytbKPRYHJyct6YH//4xwBnr3asiNgREc2IaJ49e9WhN7TFzATqlwtwGzDKVdQtkzo9fpaC5d6Bdu8g2HoL2cu+/vWv8+1vf7vKsfZk5nBmDq9YsWLR5thti5lJ63i1ygWYyMxL1zhWrTKp0+NnKVR6mz3N1mg0GB8fv7w9MTHBypUrZ41pNpuMjIwA/D3gTmBLRExl5l90capdYybtVc0F6I+I/w18nMJzca10SWb25DY0NJQ3q/feey/vuOOOPH36dF64cCE3bNiQL7/8ctuxQBN4AvhymklmLiyTrEkuQHP6P66Vmery+FmI99fKtW6VztwjYjPwH4FlwPczc9ec/dHavwX4FfBPM/Pn1/Vd5wa2fPlydu/ezaZNm7h06RIPPvgg69evZ3R0+pLpzp07ezzD7jOT9sxlPjPpkmu1P9OFfgroB/qAl4B1c8ZsAQ4BAdwD/Oxax/W7rJlUvdUhFzNpz8fPfFUzqfIL1buBscw8nZkXgX3AtjljtgFPtj73C8DHIuKT1/VdR5LUsSqXZVYB4zO2J4DPVRizCnhz5qCI2AHsaG1eiIiXFzTbm9NgrycgqX6qlHu0uW/uc5mqjCEz9wB7ACKimZnDFT7/TS0imr2eg6T6qXJZZgJYPWO7AbzRwRhJUpdUKfcXgTURcUdE9AEjwIE5Yw4A98e0e4Dzmfnm3ANJkrrjmpdlMnMqIh5m+sV7lgGPZ+bxiNjZ2j8KHGT6GTNjTD8V8oEKn3tPx7O+udTl65R0A6n0PPfMPMh0gc+8b3TGxwk8tJBP3Lr+Xry6fJ2Sbiy+towkFchyl6QC9aTcI2JzRLwaEWMR8Ugv5rDUIuLxiHirJs/ll3SD6Xq5R8Qy4FHgXmAdcF9ErOv2PLrgCWBzrychqZ56ceZe5eUMbnqZ+Rzwbq/nIameelHuH/RSBZKkRdKLcq/0UgWSpM71otx9qQJJWmK9KPcqL2cgSboOXS/3zJwC3n85g1eAP8vM492ex1KLiL3AT4HBiJiIiK/2ek6S6qMnb5Dd7uUMSpOZ9/V6DpLqy79QlaQCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHLvUERsjohXI2IsIh5ps/8fR8Sx1u0vI+LTvZhnNx0+fJjBwUEGBgbYtWvXvP0//OEP2bBhA8C6umQC1XJhOhPXSktd18qiykxvC7wBy4BTQD/QB7wErJsz5vPAba2P7wV+dq3jDg0N5c1qamoq+/v789SpU3nhwoXcsGFDHj9+fNaYn/zkJ/nuu+8m0KyaSdYkF+B/pmvlsk7Wys2cyUIAzazwuPHMvTN3A2OZeTozLwL7gG0zB2TmX2bmudbmC0Cjy3PsqiNHjjAwMEB/fz99fX2MjIywf//+WWM+//nPc9ttt72/WXwmUD0X4FJrs/hcXCvdYbl3ZhUwPmN7onXfB/kqcKjdjojYERHNiGiePXt2EafYXZOTk6xevfrydqPRYHJy8mr/5AMzAXNpt8NM5islk6VguXcm2tyXbQdG/AHTi/NP2u3PzD2ZOZyZwytWrFjEKXbX9E+Ls0W0iwmAW7lKJq3j1S4X10pbV10rpWSyFJb3egI3qQlg9YztBvDG3EERsQH4PnBvZr7Tpbn1RKPRYHz8yg8zExMTrFy5ct64Y8eOAXwK2FB6JlA9F+Bv4VqZpW5rZbF55t6ZF4E1EXFHRPQBI8CBmQMi4nbgz4E/zszXejDHrtq4cSMnT57kzJkzXLx4kX379rF169ZZY15//XW2b98OcKYOmUD1XIDfw7VyWR3XymLzzL0DmTkVEQ8DTzP9zJnHM/N4ROxs7R8F/hT4beA/tX7knMrM4V7NeaktX76c3bt3s2nTJi5dusSDDz7I+vXrGR0dBWDnzp1885vf5J133gH4VET8gsIzgeq5MP1YdK1Q37Wy2KLd9S/1xvDwcDabzV5PY8lFxNGFPFDrkIuZtLeQXMxkNi/LSFKBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcOxQRmyPi1YgYi4hH2uyPiPhOa/+xiPhsL+bZTYcPH2ZwcJCBgQF27do1b39m8rWvfQ3grrpkAtVyAVa7Vq6o61pZVJnpbYE3YBlwCugH+oCXgHVzxmwBDgEB3AP87FrHHRoaypvV1NRU9vf356lTp/LChQu5YcOGPH78+KwxTz31VG7evDmBZtVMsia5AOddK1d0slZu5kwWAmhmhceNZ+6duRsYy8zTmXkR2AdsmzNmG/Bk6//HC8DHIuKT3Z5otxw5coSBgQH6+/vp6+tjZGSE/fv3zxqzf/9+7r//fgDqkAlUzwV4x7VyRR3XymKL6W8EWoiI+DKwOTP/WWv7j4HPZebDM8b8V2BXZv6P1vYzwJ9kZnPOsXYAO1qbdwEvd+FLWAq3AR8B/qq1/beBDwOvzxgzAPwfYFVm3vpBmUAtc+nLzA+Ba6Wl0lopKJOFGMzMW681aHk3ZlKgaHPf3O+SVcaQmXuAPQAR0czM4eufXvdFxD8CNs35hnd3Zv7LGWOeAv4d8B9m/NO2Zxc1zOX35vxT10qFtVJKJgsREfNOhtrxskxnJoDVM7YbwBsdjCmJmbRXNZe+a4wpiWulCyz3zrwIrImIOyKiDxgBDswZcwC4v/WsmXuA85n5Zrcn2kWVMwGoSSZQPZffdq3MUse1sqi8LNOBzJyKiIeBp5l+5szjmXk8Ina29o8CB5l+xswY8CvggQqH3rNEU15yC8xkCPge1TKBeuTyc1wr17tWbtpMFqjS1+kvVCWpQF6WkaQCWe6SVCDL/QZxrZczKEFEPB4Rb0VEpecim0nb8cVnAubSzkIzsdxvABGxDHgUuBdYB9wXEet6O6sl8QSwucpAM5mvRpmAubTzBBUzAcv9RlHl5Qxuepn5HPBuxeFmMl8tMgFzaWeBmVjuN4hVwPiM7YnWfXVmJvOZSXvm0oblfmOo9FIFNWMm85lJe+bShuV+Y/BPreczk/nMpD1zacNyvzFU+XPsujGT+cykPXNpw3K/AWTmFPD+n2O/AvxZZh7v7awWX0TsBX4KDEbERER89YPGmsl8dckEzKWdhWQCvvyAJBXJM3dJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgr0/wFY00PHEvq2kgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "jitter = T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0, hue=0)\n",
    "jitted_imgs = [jitter(i['img']) for _ in range(4)]\n",
    "plot(jitted_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show([dog1, dog2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ColorJitter(brightness=None, contrast=None, saturation=None, hue=None)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f094a5cfaa0fb3b1e730adb1bd2a385aed1bdbc34460cd7c5bc1913497751e38"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('calc_det')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
